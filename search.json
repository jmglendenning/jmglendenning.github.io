[
  {
    "objectID": "project01.html",
    "href": "project01.html",
    "title": "Project - Brainstorming",
    "section": "",
    "text": "Here are several project ideas that combine voting, education, and health data, and lend themselves to interactive visualization in R Shiny with artistic 2D charts.\n\n\n\n\nConcept: Explore the relationship between civic participation (voting turnout) and community well-being (educational attainment, health outcomes like obesity, life expectancy, or access to healthcare).\n\nGeospatial Component: County- or state-level choropleth maps showing turnout vs.¬†health/education indices.\n\nSophisticated 2D Visualizations:\n\nChord diagrams linking regions with high turnout to health and education performance.\n\nRadar charts comparing regions across civic health indicators.\n\nInteractive beeswarm plots showing how counties cluster by turnout and well-being.\n\n\n\n\n\n\n\nConcept: Visualize how educational inequality and health disparities predict or correlate with voter participation.\n\nGeospatial Component: Optional hexbin maps to avoid irregular geographic shapes.\n\nSophisticated Visualizations:\n\nRidgeline plots comparing turnout distributions across education or health quintiles.\n\nSankey diagrams connecting educational attainment ‚Üí health outcomes ‚Üí turnout.\n\nAnimated scatter plots over time (2000‚Äì2024) showing shifting relationships.\n\n\n\n\n\n\n\nConcept: Focus on temporal change. How have turnout rates, graduation rates, and public health measures shifted together over the past decades?\n\nGeospatial Component: Time-lapse choropleths or animated small multiples by state.\n\nSophisticated Visualizations:\n\nStreamgraphs to show trends of participation vs.¬†education vs.¬†health.\n\nAlluvial plots tracking states moving between ‚Äúlow ed/low health/low vote‚Äù categories.\n\nCircular barplots for an artistic, unconventional style.\n\n\n\n\n\n\n\nConcept: Examine whether educational attainment and health outcomes correlate with swing state behavior in elections (close margins, shifts between parties).\n\nGeospatial Component: State-level cartograms emphasizing electoral votes rather than land area.\n\nSophisticated Visualizations:\n\nHexbin scatterplots of turnout vs.¬†education/health metrics with party overlays.\n\nDensity contour plots emphasizing clusters of swing vs.¬†safe states.\n\nInteractive ternary plots (education, health, voting as vertices).\n\n\n\n\n\n\n\nConcept: Identify areas where low education, poor health, and low turnout overlap (‚Äúcivic deserts‚Äù) vs.¬†areas with high values on all three (‚Äúcivic gardens‚Äù).\n\nGeospatial Component: Interactive maps highlighting these clusters.\n\nSophisticated Visualizations:\n\nVoronoi diagrams to map ‚Äúcivic desert‚Äù zones without strict boundaries.\n\nTreemaps or sunbursts showing nested categories (education ‚Üí health ‚Üí turnout).\n\nPolar coordinate plots for community comparisons.\n\n\n\n\n\n\n\nConcept: Investigate whether counties/states with higher or lower life expectancy tend to vote differently and whether education mediates this effect.\n\nGeospatial Component: Interactive choropleths by county with linked scatterplots.\n\nSophisticated Visualizations:\n\nBubble plots in polar coordinates to highlight clustering.\n\nHeatmaps with dendrograms showing cross-indicator correlations.\n\nInteractive slopegraphs showing turnout and life expectancy changes.\n\n\n\n\n\n\nTo make the visualizations sophisticated, artistic, and attractive: - Use custom color palettes (viridis, wesanderson, scientific palettes).\n- Explore non-traditional layouts (circular, radial, layered).\n- Add interactive storytelling: clicking on a region brings up linked health/education/voting histories.\n\n\n\nHere is a curated table list from IPUMS NHGIS that aligns with your project‚Äôs goals for identifying civic deserts and civic gardens at the county level, using the domains of education, health, and voter turnout (via external source).\n‚∏ª\nüßæ IPUMS NHGIS Table List\nThese tables are from ACS 5-Year Estimates, which provide the most detailed and stable county-level data.\n\nEducation\n\nTable ID Table Title Key Columns B15003 Educational Attainment for the Population 25 Years and Over Count of individuals by highest level of education completed C15002 Sex by Educational Attainment for the Population 25 Years and Over Gender comparison (optional) S1501 Educational Attainment Summary Table Percent with &lt; HS, HS, Some College, BA+, etc.\n‚∏ª\n\nHealth (Proxies)\n\nTable ID Table Title Key Columns S1810 Disability Characteristics % with hearing, vision, cognitive, ambulatory, self-care, independent living difficulties B27010 Types of Health Insurance Coverage by Age % uninsured, private, public insurance S2701 Health Insurance Coverage Summary Coverage breakdowns by age and gender\nüí° Note: If needed, supplement with CDC PLACES or County Health Rankings for obesity, diabetes, poor health days, etc.\n‚∏ª\n\nTurnout\n\nNo direct IPUMS NHGIS table provides turnout, so use external data and join by FIPS:\nSource Metric Notes MIT Election Lab Total votes / Voting-age population (VAP) County-level turnout in general elections Harvard Election Data Archive Voter turnout Also includes registration and vote choice by county State Election Offices For state-specific turnout rates Check Secretary of State or elections board\n‚∏ª\n\nGeographic Identifiers & Population\n\nTable ID Table Title Key Columns B01001 Sex by Age Use total count for denominator in rates (e.g., % uninsured) ‚Äî County shapefiles Download with ‚ÄúNHGIS Boundary Files‚Äù (match via GISJOIN or FIPS)\n‚∏ª\nOptional Enhancements\nDomain Table Use Poverty S1701 Correlate with civic deserts Employment S2301 Add context (e.g., joblessness and civic disengagement) Language B16004 Language isolation may correlate with civic participation\n‚∏ª\nFinal Package\nWhen ordering from IPUMS NHGIS: ‚Ä¢ Use the Data Finder tool ‚Ä¢ Select ACS 5-Year Estimates ‚Ä¢ Filter by County geographic level ‚Ä¢ Include tables: ‚Ä¢ B15003, S1501, S1810, B27010, S2701, B01001, plus any others above ‚Ä¢ Include 2020 boundaries (or consistent year across tables)\n‚∏ª\nWould you like me to generate a pre-filled download script for NHGIS or help prep these for use in a Shiny app or Quarto dashboard?"
  },
  {
    "objectID": "project01.html#civic-health-dashboard",
    "href": "project01.html#civic-health-dashboard",
    "title": "Project - Brainstorming",
    "section": "",
    "text": "Concept: Explore the relationship between civic participation (voting turnout) and community well-being (educational attainment, health outcomes like obesity, life expectancy, or access to healthcare).\n\nGeospatial Component: County- or state-level choropleth maps showing turnout vs.¬†health/education indices.\n\nSophisticated 2D Visualizations:\n\nChord diagrams linking regions with high turnout to health and education performance.\n\nRadar charts comparing regions across civic health indicators.\n\nInteractive beeswarm plots showing how counties cluster by turnout and well-being."
  },
  {
    "objectID": "project01.html#the-social-gradient-in-democracy",
    "href": "project01.html#the-social-gradient-in-democracy",
    "title": "Project - Brainstorming",
    "section": "",
    "text": "Concept: Visualize how educational inequality and health disparities predict or correlate with voter participation.\n\nGeospatial Component: Optional hexbin maps to avoid irregular geographic shapes.\n\nSophisticated Visualizations:\n\nRidgeline plots comparing turnout distributions across education or health quintiles.\n\nSankey diagrams connecting educational attainment ‚Üí health outcomes ‚Üí turnout.\n\nAnimated scatter plots over time (2000‚Äì2024) showing shifting relationships."
  },
  {
    "objectID": "project01.html#education-health-and-the-vote-over-time",
    "href": "project01.html#education-health-and-the-vote-over-time",
    "title": "Project - Brainstorming",
    "section": "",
    "text": "Concept: Focus on temporal change. How have turnout rates, graduation rates, and public health measures shifted together over the past decades?\n\nGeospatial Component: Time-lapse choropleths or animated small multiples by state.\n\nSophisticated Visualizations:\n\nStreamgraphs to show trends of participation vs.¬†education vs.¬†health.\n\nAlluvial plots tracking states moving between ‚Äúlow ed/low health/low vote‚Äù categories.\n\nCircular barplots for an artistic, unconventional style."
  },
  {
    "objectID": "project01.html#education-health-as-predictors-of-swing-state-outcomes",
    "href": "project01.html#education-health-as-predictors-of-swing-state-outcomes",
    "title": "Project - Brainstorming",
    "section": "",
    "text": "Concept: Examine whether educational attainment and health outcomes correlate with swing state behavior in elections (close margins, shifts between parties).\n\nGeospatial Component: State-level cartograms emphasizing electoral votes rather than land area.\n\nSophisticated Visualizations:\n\nHexbin scatterplots of turnout vs.¬†education/health metrics with party overlays.\n\nDensity contour plots emphasizing clusters of swing vs.¬†safe states.\n\nInteractive ternary plots (education, health, voting as vertices)."
  },
  {
    "objectID": "project01.html#civic-deserts-and-civic-gardens",
    "href": "project01.html#civic-deserts-and-civic-gardens",
    "title": "Project - Brainstorming",
    "section": "",
    "text": "Concept: Identify areas where low education, poor health, and low turnout overlap (‚Äúcivic deserts‚Äù) vs.¬†areas with high values on all three (‚Äúcivic gardens‚Äù).\n\nGeospatial Component: Interactive maps highlighting these clusters.\n\nSophisticated Visualizations:\n\nVoronoi diagrams to map ‚Äúcivic desert‚Äù zones without strict boundaries.\n\nTreemaps or sunbursts showing nested categories (education ‚Üí health ‚Üí turnout).\n\nPolar coordinate plots for community comparisons."
  },
  {
    "objectID": "project01.html#life-expectancy-and-the-vote",
    "href": "project01.html#life-expectancy-and-the-vote",
    "title": "Project - Brainstorming",
    "section": "",
    "text": "Concept: Investigate whether counties/states with higher or lower life expectancy tend to vote differently and whether education mediates this effect.\n\nGeospatial Component: Interactive choropleths by county with linked scatterplots.\n\nSophisticated Visualizations:\n\nBubble plots in polar coordinates to highlight clustering.\n\nHeatmaps with dendrograms showing cross-indicator correlations.\n\nInteractive slopegraphs showing turnout and life expectancy changes."
  },
  {
    "objectID": "project01.html#additions",
    "href": "project01.html#additions",
    "title": "Project - Brainstorming",
    "section": "",
    "text": "To make the visualizations sophisticated, artistic, and attractive: - Use custom color palettes (viridis, wesanderson, scientific palettes).\n- Explore non-traditional layouts (circular, radial, layered).\n- Add interactive storytelling: clicking on a region brings up linked health/education/voting histories."
  },
  {
    "objectID": "project01.html#datasets-for-option-5",
    "href": "project01.html#datasets-for-option-5",
    "title": "Project - Brainstorming",
    "section": "",
    "text": "Here is a curated table list from IPUMS NHGIS that aligns with your project‚Äôs goals for identifying civic deserts and civic gardens at the county level, using the domains of education, health, and voter turnout (via external source).\n‚∏ª\nüßæ IPUMS NHGIS Table List\nThese tables are from ACS 5-Year Estimates, which provide the most detailed and stable county-level data.\n\nEducation\n\nTable ID Table Title Key Columns B15003 Educational Attainment for the Population 25 Years and Over Count of individuals by highest level of education completed C15002 Sex by Educational Attainment for the Population 25 Years and Over Gender comparison (optional) S1501 Educational Attainment Summary Table Percent with &lt; HS, HS, Some College, BA+, etc.\n‚∏ª\n\nHealth (Proxies)\n\nTable ID Table Title Key Columns S1810 Disability Characteristics % with hearing, vision, cognitive, ambulatory, self-care, independent living difficulties B27010 Types of Health Insurance Coverage by Age % uninsured, private, public insurance S2701 Health Insurance Coverage Summary Coverage breakdowns by age and gender\nüí° Note: If needed, supplement with CDC PLACES or County Health Rankings for obesity, diabetes, poor health days, etc.\n‚∏ª\n\nTurnout\n\nNo direct IPUMS NHGIS table provides turnout, so use external data and join by FIPS:\nSource Metric Notes MIT Election Lab Total votes / Voting-age population (VAP) County-level turnout in general elections Harvard Election Data Archive Voter turnout Also includes registration and vote choice by county State Election Offices For state-specific turnout rates Check Secretary of State or elections board\n‚∏ª\n\nGeographic Identifiers & Population\n\nTable ID Table Title Key Columns B01001 Sex by Age Use total count for denominator in rates (e.g., % uninsured) ‚Äî County shapefiles Download with ‚ÄúNHGIS Boundary Files‚Äù (match via GISJOIN or FIPS)\n‚∏ª\nOptional Enhancements\nDomain Table Use Poverty S1701 Correlate with civic deserts Employment S2301 Add context (e.g., joblessness and civic disengagement) Language B16004 Language isolation may correlate with civic participation\n‚∏ª\nFinal Package\nWhen ordering from IPUMS NHGIS: ‚Ä¢ Use the Data Finder tool ‚Ä¢ Select ACS 5-Year Estimates ‚Ä¢ Filter by County geographic level ‚Ä¢ Include tables: ‚Ä¢ B15003, S1501, S1810, B27010, S2701, B01001, plus any others above ‚Ä¢ Include 2020 boundaries (or consistent year across tables)\n‚∏ª\nWould you like me to generate a pre-filled download script for NHGIS or help prep these for use in a Shiny app or Quarto dashboard?"
  },
  {
    "objectID": "coins01.html",
    "href": "coins01.html",
    "title": "Project - Brainstorming",
    "section": "",
    "text": "This project was a comprehensive analysis of the spatial distribution of coinage originating from various mints and subsequently deposited in hoards across the Roman world between approximately 500 BCE and 200 CE. By examining patterns in coin dispersal and quantifying the distances between points of minting and findspots, the study aimed to examine the broader dynamics of monetary circulation, and economic integration within the Roman economy. The ultimate objective was to generate insights into the mechanisms of coin movement and to contribute to our understanding of the structure and function of the ancient Roman economic system.\nThe first step that I‚Äôd like to look at is the probability of a coin existing in a certain location base on hoard finds.\nNote that there are several errors and mislabeled figures in this. This is for discussion purposes only."
  },
  {
    "objectID": "coins01.html#data-source",
    "href": "coins01.html#data-source",
    "title": "Project - Brainstorming",
    "section": "Data Source",
    "text": "Data Source\nFor the initial analysis, the data from the Coin Hoards of the Roman Republic was accessed. This dataset is based of the work of Crawford (1969), as enhanced by Gruber and Lockyear.\nThis data can be accessed via the website‚Äôs APIs or via the SPARQL endpoint at Nomisma. Not all hoards were appropriate for analysis. This initial analysis only included hoard findspots that had the following:\n\nGeolocation of hoard\nAt least 1 coin with a known mint\nKnown mint geolocation\n\nThe findspot information was mostly within a 5 kilometer radius of the findspot. Some was 10 km, but that was less often. For security reasons, the exact geolocation was never directly published to prevent theft and looting.\nFor now, all the findspots meeting the criteria were used, but this may be narrowed in the future."
  },
  {
    "objectID": "coins01.html#data-acquisition",
    "href": "coins01.html#data-acquisition",
    "title": "Project - Brainstorming",
    "section": "Data Acquisition",
    "text": "Data Acquisition\nTo acquire the data, first a list of all the hoards in the CHRR dataset was gathered from the SPARQL endpoint.\n\nPREFIX dcterms: &lt;http://purl.org/dc/terms/&gt;\nPREFIX nmo: &lt;http://nomisma.org/ontology#&gt;\n\nSELECT DISTINCT ?hoardID\nWHERE {\n  ?hoard a nmo:Hoard .\n  FILTER(STRSTARTS(STR(?hoard), \"http://numismatics.org/chrr/id/\"))\n  BIND(REPLACE(STR(?hoard), \"http://numismatics.org/chrr/id/\", \"\") AS ?hoardID)\n}\nORDER BY ?hoardID\n\nUsing the list of three digit hoard identifiers from this list, an R program was written to download all of the identified hoards using the schema:\n# ---- 3. Define File Formats and URI Templates ----\nformats &lt;- list(\n  xml     = \"http://numismatics.org/chrr/id/XXX\",\n  rdf     = \"https://numismatics.org/chrr/id/XXX.rdf\",\n  ttl     = \"https://numismatics.org/chrr/id/XXX.ttl\",\n  jsonld  = \"https://numismatics.org/chrr/id/XXX.jsonld\",\n  geojson = \"https://numismatics.org/chrr/id/XXX.geojson\"\n)\n‚ÄòXXX‚Äô was replaced by the three digit hoard identifier.\nExample hoard identifier list:\n...\nAVO\nAVV\nAVZ\nAZA\nAZN\nAZU\n...\nAll of the RDF/XML, TTL, JSON-LD, and GeoJSON data were gathered for the hoards. The code for this is not included in this file.\nFrom this dataset, all the coin identifiers in the dataset were extracted. The URIs were in the form:\n\n# ---- 3. Define Format URIs ----\nformat_urls &lt;- list(\n  xml      = \"http://numismatics.org/crro/id/XXX.xml\",\n  rdf      = \"https://numismatics.org/crro/id/XXX.rdf\",\n  ttl      = \"https://numismatics.org/crro/id/XXX.ttl\",\n  jsonld   = \"https://numismatics.org/crro/id/XXX.jsonld\",\n  geojson  = \"https://numismatics.org/crro/id/XXX.geojson\",\n  manifest = \"http://numismatics.org/crro/manifest/XXX\"\n)\n\nThe coin ids, which replaced the XXX above, were in the form:\n...\nrrc-210.1\nrrc-214.1b\nrrc-232.1\nrrc-235.1c\nrrc-236.1a\nrrc-243.1\nrrc-247.1\nrrc-260.1\nrrc-270.1\n...\n\nAll of the RDF/XML, TTL, JSON-LD, and GeoJSON data were gathered for the hoards. The code for this is not included in this file.\nIn addition"
  },
  {
    "objectID": "coins01.html#data-processing",
    "href": "coins01.html#data-processing",
    "title": "Project - Brainstorming",
    "section": "Data Processing",
    "text": "Data Processing\nThe a sample of the initial set of data looks like:\n\n# Load the data\nhoards_df &lt;- read_csv(\"/Users/john/Library/Mobile Documents/com~apple~CloudDocs/Home/John/GIS/Roman Italy GIS/Coin Project/chrr_hoards/hoard_geojson/combined_hoards_with_distance.csv\")\n\nRows: 926 Columns: 13\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (7): hoard_id, hoard_name, hoard_uri, hoard_geometry, mint_name, mint_ur...\ndbl (6): hoard_lat, hoard_lon, mint_average_count, mint_lat, mint_lon, mint_...\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Filter for Rome mint, take first 20 rows, keep all columns\nrome_subset &lt;- hoards_df %&gt;%\n  filter(mint_name == \"Rome\") %&gt;%\n  slice_head(n = 10)\n\n# Print as a nicely formatted table\nkable(rome_subset, caption = \"First 20 Hoards with Rome as Mint\")\n\n\nFirst 20 Hoards with Rome as Mint\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhoard_id\nhoard_name\nhoard_uri\nhoard_lat\nhoard_lon\nhoard_geometry\nmint_name\nmint_uri\nmint_average_count\nmint_lat\nmint_lon\nmint_geometry\nmint_hoard_distance_km\n\n\n\n\n1PO\nPoiana CrƒÉcƒÉoani (Romania)\nhttps://sws.geonames.org/670093/\n47.06667\n26.31667\nPOINT (26.31667 47.06667)\nRome\nhttp://nomisma.org/id/rome\n123\n41.9\n12.5\nPOINT (12.5 41.9)\n1236.48816\n\n\nABE\nAbertura (Spain)\nhttps://sws.geonames.org/2522486/\n39.24352\n-5.81394\nPOINT (-5.81394 39.24352)\nRome\nhttp://nomisma.org/id/rome\n23\n41.9\n12.5\nPOINT (12.5 41.9)\n1573.37081\n\n\nACT\n√Åktion (Greece)\nhttps://sws.geonames.org/265389/\n38.94019\n20.76875\nPOINT (20.76875 38.94019)\nRome\nhttp://nomisma.org/id/rome\n3\n41.9\n12.5\nPOINT (12.5 41.9)\n773.90425\n\n\nADJ\nAmƒÉrƒÉ≈ütii de Jos (Romania)\nhttps://sws.geonames.org/686386/\n43.95000\n24.16667\nPOINT (24.16667 43.95)\nRome\nhttp://nomisma.org/id/rome\n4\n41.9\n12.5\nPOINT (12.5 41.9)\n977.06559\n\n\nADM\nMassa d‚ÄôAlbe (Italy)\nhttps://sws.geonames.org/3173765/\n42.10723\n13.39429\nPOINT (13.39429 42.10723)\nRome\nhttp://nomisma.org/id/rome\n93\n41.9\n12.5\nPOINT (12.5 41.9)\n77.49022\n\n\nADR\nAlcal√° del R√≠o (Spain)\nhttps://sws.geonames.org/2522474/\n37.51780\n-5.98185\nPOINT (-5.98185 37.5178)\nRome\nhttp://nomisma.org/id/rome\n159\n41.9\n12.5\nPOINT (12.5 41.9)\n1652.39657\n\n\nADU\nAlbanchez de M√°gina (Spain)\nhttps://sws.geonames.org/2522239/\n37.79263\n-3.46833\nPOINT (-3.46833 37.79263)\nRome\nhttp://nomisma.org/id/rome\n16\n41.9\n12.5\nPOINT (12.5 41.9)\n1436.74096\n\n\nAGG\nAggius (Italy)\nhttps://sws.geonames.org/3183443/\n40.92995\n9.06517\nPOINT (9.06517 40.92995)\nRome\nhttp://nomisma.org/id/rome\n10\n41.9\n12.5\nPOINT (12.5 41.9)\n306.37972\n\n\nAGN\nAgnona (Italy)\nhttps://sws.geonames.org/6693917/\n45.72602\n8.25957\nPOINT (8.25957 45.72602)\nRome\nhttp://nomisma.org/id/rome\n244\n41.9\n12.5\nPOINT (12.5 41.9)\n545.19648\n\n\nAID\nAid√≥na (Greece)\nhttps://sws.geonames.org/265542/\n39.60542\n21.46797\nPOINT (21.46797 39.60542)\nRome\nhttp://nomisma.org/id/rome\n4\n41.9\n12.5\nPOINT (12.5 41.9)\n797.75946\n\n\n\n\n\nThis is limited only to hoards with coins from the Rome mint, and the distance is crudely calculated as the great circle distance. We expect to use ORBIS to more accurately model transportation networks and distances.\nThere is more granular data that includes Terminus Ante Quem (closing date), specific coin types and authorities, and dates. This has not yet been combined into the data set.\nIt is expected that there would be some spatial autocorrelation of the data since there is the expectation that coins would not be distributed along whatever routes they took to their final destination in the hoard."
  },
  {
    "objectID": "coins01.html#mints",
    "href": "coins01.html#mints",
    "title": "Project - Brainstorming",
    "section": "Mints",
    "text": "Mints"
  },
  {
    "objectID": "coins01.html#all-hoard-findspots",
    "href": "coins01.html#all-hoard-findspots",
    "title": "Project - Brainstorming",
    "section": "All Hoard Findspots",
    "text": "All Hoard Findspots"
  },
  {
    "objectID": "coins01.html#spatial-autocorrelation",
    "href": "coins01.html#spatial-autocorrelation",
    "title": "Project - Brainstorming",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\n\n\nRows: 926 Columns: 13\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (7): hoard_id, hoard_name, hoard_uri, hoard_geometry, mint_name, mint_ur...\ndbl (6): hoard_lat, hoard_lon, mint_average_count, mint_lat, mint_lon, mint_...\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nData Quality Summary:\n\n\nTotal hoards: 486 \n\n\nPresence distribution:\n\n\n\n  0   1 \n  3 483 \n\n\nMissing coordinates: 0 \n\n\nProportion with Rome mint presence: 0.994 \n\n\n\nTesting multiple distance thresholds:\n\n\nWarning in dnearneigh(coords, d1 = 0, d2 = dist): neighbour object has 84\nsub-graphs\n\n\nWarning in dnearneigh(coords, d1 = 0, d2 = dist): neighbour object has 49\nsub-graphs\n\n\nWarning in dnearneigh(coords, d1 = 0, d2 = dist): neighbour object has 28\nsub-graphs\n\n\nWarning in dnearneigh(coords, d1 = 0, d2 = dist): neighbour object has 16\nsub-graphs\n\n\nWarning in dnearneigh(coords, d1 = 0, d2 = dist): neighbour object has 13\nsub-graphs\n\n\n  distance_km moran_i p_value islands avg_neighbors\n1         100      NA      NA      58            NA\n2         150      NA      NA      29            NA\n3         200      NA      NA      15            NA\n4         250      NA      NA      11            NA\n5         300      NA      NA      10            NA\n\n\nWarning in dnearneigh(coords, d1 = 0, d2 = optimal_distance): neighbour object\nhas 28 sub-graphs\n\n\n\nSpatial neighborhood summary:\n\n\nDistance threshold: 200 km\n\n\nNumber of points with no neighbors: 15 \n\n\nAverage number of neighbors: 23.66 \n\n\nRange of neighbors: 0 - 56 \n\n\n\nGlobal Moran's I Results:\n\n\nRow-standardized weights:\n\n\n\n    Moran I test under randomisation\n\ndata:  rome_proj$presence  \nweights: lw  \nn reduced by no-neighbour observations  \n\nMoran I statistic standard deviate = 0.83075, p-value = 0.2031\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.0123304614     -0.0021276596      0.0003028863 \n\n\n\nBinary weights:\n\n\n\n    Moran I test under randomisation\n\ndata:  rome_proj$presence  \nweights: lw_binary  \nn reduced by no-neighbour observations  \n\nMoran I statistic standard deviate = 1.5754, p-value = 0.05758\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.0141599037     -0.0021276596      0.0001068888 \n\n\n\nComputing Local Moran's I...\n\n\n\nCluster Summary (original p-values):\n\n\n\n       High-Low         Low-Low Not significant \n             33               2             451 \n\n\n\nCluster Summary (FDR-adjusted p-values):\n\n\n\n       High-Low Not significant \n             20             466 \n\n\n\nSignificance levels:\n\n\n\nNot significant        p &lt; 0.01        p &lt; 0.05 \n            451              23              12 \n\n\n‚Ñπ tmap modes \"plot\" - \"view\"\n‚Ñπ toggle with `tmap::ttm()`\n‚Ñπ tmap modes \"plot\" - \"view\"\n\n\nWarning: tm_scale_intervals `label.style = \"continuous\"` implementation in view mode\nwork in progress\n\n\n\n\n\n\n\nMultiple palettes called \"gray\" found: \"matplotlib.gray\", \"tableau.gray\", \"ocean.gray\", \"gmt.gray\". The first one, \"matplotlib.gray\", is returned.\nMultiple palettes called \"gray\" found: \"matplotlib.gray\", \"tableau.gray\", \"ocean.gray\", \"gmt.gray\". The first one, \"matplotlib.gray\", is returned.\n\n\nWarning: tm_scale_intervals `label.style = \"continuous\"` implementation in view mode\nwork in progress\n\n\n\n\n\n\n\n\n\n\nAlternative analysis with k-nearest neighbors:\n\n\nWarning in knearneigh(coords, k = k): knearneigh: identical points found\n\n\nWarning in knearneigh(coords, k = k): knearneigh: kd_tree not available for\nidentical points\n\n\nWarning in knearneigh(coords, k = k): knearneigh: identical points found\n\n\nWarning in knearneigh(coords, k = k): knearneigh: kd_tree not available for\nidentical points\n\n\nWarning in knearneigh(coords, k = k): knearneigh: identical points found\n\n\nWarning in knearneigh(coords, k = k): knearneigh: kd_tree not available for\nidentical points\n\n\nWarning in knearneigh(coords, k = k): knearneigh: identical points found\n\n\nWarning in knearneigh(coords, k = k): knearneigh: kd_tree not available for\nidentical points\n\n\n                    k      moran_i   p_value\nMoran I statistic   6 -0.007936508 0.6165404\nMoran I statistic1  8 -0.009316770 0.6642648\nMoran I statistic2 10 -0.008695652 0.6677864\nMoran I statistic3 12 -0.008626639 0.6811293\n\n\n\nDiagnostics:\n\n\nDistribution of presence variable:\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  1.0000  1.0000  0.9938  1.0000  1.0000 \n\n\n\nLocal Moran's I statistics summary:\n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-1.000000  0.006211  0.006211  0.012330  0.006211  4.225807 \n\n\n\nSignificant clusters by type:\n\n\n\nHigh-Low  Low-Low \n      33        2"
  },
  {
    "objectID": "coins01.html#kriging-probability-surface",
    "href": "coins01.html#kriging-probability-surface",
    "title": "Project - Brainstorming",
    "section": "Kriging / probability surface",
    "text": "Kriging / probability surface\nThis is not functional. I have developed some code but it does not work well.\nI am trying to use indicator Kriging, but I am running into trouble excuting the analysis. I only have places that have coins, and a few that don‚Äôt have coins from the Rome mint. I don‚Äôt think I have enough data."
  },
  {
    "objectID": "coins01.html#distance-decay",
    "href": "coins01.html#distance-decay",
    "title": "Project - Brainstorming",
    "section": "Distance Decay",
    "text": "Distance Decay\n\n# Roman Coin Probability Surface Analysis with Hex Binning\n# Load required libraries\nlibrary(sf)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(readr)\nlibrary(viridis)\n\nLoading required package: viridisLite\n\n# Try to load optional basemap packages\nbasemap_packages &lt;- c(\"rnaturalearth\", \"rnaturalearthdata\", \"maps\")\navailable_packages &lt;- sapply(basemap_packages, function(pkg) {\n  suppressWarnings(require(pkg, character.only = TRUE, quietly = TRUE))\n})\n\n\nAttaching package: 'maps'\n\n\nThe following object is masked from 'package:viridis':\n\n    unemp\n\nif(!any(available_packages)) {\n  warning(\"No basemap packages available. Install 'rnaturalearth' or 'maps' for geographic context.\")\n}\n\n# Resolve potential conflicts\nselect &lt;- dplyr::select\nfilter &lt;- dplyr::filter\nmutate &lt;- dplyr::mutate\n\n# Read and prepare data\ndata &lt;- readr::read_csv(\"/Users/john/Library/Mobile Documents/com~apple~CloudDocs/Home/John/GIS/Roman Italy GIS/Coin Project/chrr_hoards/hoard_geojson/combined_hoards_with_distance.csv\")\n\nRows: 926 Columns: 13\n\n\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (7): hoard_id, hoard_name, hoard_uri, hoard_geometry, mint_name, mint_ur...\ndbl (6): hoard_lat, hoard_lon, mint_average_count, mint_lat, mint_lon, mint_...\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Focus on Rome mint only\nrome_data &lt;- data %&gt;%\n  dplyr::filter(mint_name == \"Rome\") %&gt;%\n  dplyr::select(hoard_id, hoard_name, hoard_lat, hoard_lon, \n                mint_average_count, mint_hoard_distance_km)\n\n# Convert findspots to spatial points\nfindspots_sf &lt;- st_as_sf(rome_data, \n                         coords = c(\"hoard_lon\", \"hoard_lat\"), \n                         crs = 4326)\n\n# Create hexagonal grid function\ncreate_hex_grid &lt;- function(bbox, hex_size_km = 75) {\n  # Convert to projected CRS for equal area hexagons (Europe-focused)\n  bbox_proj &lt;- st_transform(st_as_sfc(bbox), crs = 3035)\n  \n  # Create hex grid\n  hex_grid &lt;- st_make_grid(bbox_proj, \n                           cellsize = hex_size_km * 1000, # convert to meters\n                           square = FALSE) # hexagonal\n  \n  # Convert back to WGS84 and add IDs\n  hex_grid &lt;- st_sf(hex_id = 1:length(hex_grid), \n                    geometry = st_transform(hex_grid, crs = 4326))\n  return(hex_grid)\n}\n\n# Create study area bounding box (expand around findspots)\nbbox &lt;- st_bbox(findspots_sf)\nbbox_expanded &lt;- bbox + c(-2, -2, 2, 2)  # expand by 2 degrees\nstudy_area &lt;- st_as_sfc(st_bbox(bbox_expanded, crs = st_crs(findspots_sf)))\n\n# Create hex grid\nhex_grid &lt;- create_hex_grid(bbox_expanded, hex_size_km = 75)\n\n# Spatial join: assign each findspot to a hex\nfindspots_hex &lt;- st_join(findspots_sf, hex_grid)\n\n# Aggregate data by hex\nhex_summary &lt;- findspots_hex %&gt;%\n  sf::st_drop_geometry() %&gt;%\n  dplyr::group_by(hex_id) %&gt;%\n  dplyr::summarise(\n    total_coins = sum(mint_average_count, na.rm = TRUE),\n    n_findspots = n(),\n    avg_distance_to_rome = mean(mint_hoard_distance_km, na.rm = TRUE),\n    .groups = 'drop'\n  )\n\n# Join aggregated data back to hex grid\nhex_grid &lt;- hex_grid %&gt;%\n  dplyr::left_join(hex_summary, by = \"hex_id\") %&gt;%\n  dplyr::mutate(\n    total_coins = ifelse(is.na(total_coins), 0, total_coins),\n    has_findspots = !is.na(n_findspots)\n  )\n\n# Calculate distance from each hex centroid to Rome\nrome_coords &lt;- st_sfc(st_point(c(12.5, 41.9)), crs = 4326)\n\nhex_grid &lt;- hex_grid %&gt;%\n  dplyr::mutate(\n    dist_to_rome = as.numeric(sf::st_distance(sf::st_centroid(.), rome_coords)) / 1000\n  )\n\nWarning: There was 1 warning in `stopifnot()`.\n‚Ñπ In argument: `dist_to_rome = as.numeric(sf::st_distance(sf::st_centroid(.),\n  rome_coords))/1000`.\nCaused by warning:\n! st_centroid assumes attributes are constant over geometries\n\n# Fit distance decay model using hexes with actual data\nmodel_data &lt;- hex_grid %&gt;%\n  dplyr::filter(has_findspots == TRUE & total_coins &gt; 0) %&gt;%\n  sf::st_drop_geometry()\n\n# Check if we have enough data for modeling\nif(nrow(model_data) &lt; 3) {\n  stop(\"Not enough data points for modeling. Need at least 3 hexes with coin data.\")\n}\n\n# Fit exponential decay model\n# Try different starting parameters if the first attempt fails\ntryCatch({\n  decay_model &lt;- nls(total_coins ~ a * exp(-b * dist_to_rome), \n                     data = model_data,\n                     start = list(a = max(model_data$total_coins), b = 0.001))\n}, error = function(e) {\n  # Alternative: simple linear model on log scale\n  decay_model &lt;- lm(log(total_coins + 1) ~ dist_to_rome, data = model_data)\n})\n\n# Predict for all hexes\nif(class(decay_model)[1] == \"nls\") {\n  hex_grid$predicted_coins &lt;- predict(decay_model, \n                                      newdata = data.frame(dist_to_rome = hex_grid$dist_to_rome))\n} else {\n  # For linear model, back-transform predictions\n  hex_grid$predicted_coins &lt;- exp(predict(decay_model, \n                                          newdata = data.frame(dist_to_rome = hex_grid$dist_to_rome))) - 1\n}\n\n# Create probability surface (normalize to 0-1)\nhex_grid$probability &lt;- pmax(0, hex_grid$predicted_coins) / max(pmax(0, hex_grid$predicted_coins))\n\n# Combine observed and predicted values\nhex_grid$final_coins &lt;- ifelse(hex_grid$has_findspots, \n                               hex_grid$total_coins, \n                               hex_grid$predicted_coins)\n\nhex_grid$final_probability &lt;- hex_grid$final_coins / max(hex_grid$final_coins)\n\n# Get basemap data (with error handling)\nworld &lt;- NULL\nbasemap_available &lt;- FALSE\n\n# Try Natural Earth first\nif(available_packages[\"rnaturalearth\"]) {\n  tryCatch({\n    world &lt;- rnaturalearth::ne_countries(scale = \"medium\", returnclass = \"sf\")\n    basemap_available &lt;- TRUE\n  }, error = function(e) {\n    message(\"Natural Earth data not available, trying maps package...\")\n  })\n}\n\n# Try maps package as fallback\nif(!basemap_available && available_packages[\"maps\"]) {\n  tryCatch({\n    world_map &lt;- maps::map(\"world\", fill = TRUE, plot = FALSE)\n    world &lt;- sf::st_as_sf(world_map)\n    basemap_available &lt;- TRUE\n  }, error = function(e) {\n    message(\"Maps package not working, proceeding without basemap...\")\n  })\n}\n\n# Create study area boundary for clipping\nstudy_bbox &lt;- sf::st_bbox(hex_grid)\nstudy_area_poly &lt;- sf::st_as_sfc(study_bbox)\n\n# Create visualization with optional basemap\nif(basemap_available) {\n  p1 &lt;- ggplot() +\n    # Add basemap first\n    geom_sf(data = world, fill = \"grey90\", color = \"grey95\", size = 0.2) +\n    # Add hex grid\n    geom_sf(data = hex_grid, aes(fill = final_probability), \n            color = \"white\", size = 0.1, alpha = 0.8) +\n    scale_fill_viridis_c(name = \"Coin\\nProbability\", \n                         trans = \"sqrt\",\n                         option = \"turbo\",\n                         labels = scales::percent) +\n    # Add findspot points\n    geom_sf(data = findspots_sf, size = 1, alpha = 0.9, color = \"white\") +\n    # Add Rome\n    geom_sf(data = rome_coords, size = 4, color = \"red\", shape = 18) +\n    # Set map extent to study area\n    coord_sf(xlim = c(study_bbox[\"xmin\"], study_bbox[\"xmax\"]),\n             ylim = c(study_bbox[\"ymin\"], study_bbox[\"ymax\"]),\n             expand = FALSE) +\n    theme_void() +\n    theme(\n      legend.position = \"right\",\n      plot.title = element_text(size = 14, hjust = 0.5),\n      plot.subtitle = element_text(size = 12, hjust = 0.5),\n      panel.background = element_rect(fill = \"lightblue\", color = NA)\n    ) +\n    labs(title = \"Probability Surface for Roman Coins\",\n         subtitle = \"Hexagonal binning with distance decay model from Rome\")\n} else {\n  # Fallback map without basemap\n  p1 &lt;- ggplot(hex_grid) +\n    geom_sf(aes(fill = final_probability), color = \"white\", size = 0.1) +\n    scale_fill_viridis_c(name = \"Coin\\nProbability\", \n                         trans = \"sqrt\",\n                         option = \"turbo\",\n                         labels = scales::percent) +\n    geom_sf(data = findspots_sf, size = 1, alpha = 0.8, color = \"white\") +\n    geom_sf(data = rome_coords, size = 4, color = \"red\", shape = 18) +\n    theme_void() +\n    theme(\n      legend.position = \"right\",\n      plot.title = element_text(size = 14, hjust = 0.5),\n      plot.subtitle = element_text(size = 12, hjust = 0.5)\n    ) +\n    labs(title = \"Probability Surface for Roman Coins\",\n         subtitle = \"Hexagonal binning with distance decay model from Rome\",\n         caption = \"Note: Install 'rnaturalearth' or 'maps' package for geographic context\")\n}\n\nprint(p1)\n\n\n\n\n\n\n\n# Create enhanced version if basemap is available\nif(basemap_available) {\n  p1_labeled &lt;- ggplot() +\n    # Add basemap\n    geom_sf(data = world, fill = \"grey90\", color = \"grey95\", size = 0.2) +\n    # Add hex grid\n    geom_sf(data = hex_grid, aes(fill = final_probability), \n            color = \"white\", size = 0.1, alpha = 0.8) +\n    scale_fill_viridis_c(name = \"Coin\\nProbability\", \n                         trans = \"sqrt\",\n                         option = \"plasma\",\n                         labels = scales::percent) +\n    # Add findspot points\n    geom_sf(data = findspots_sf, size = 1.2, alpha = 0.9, color = \"white\") +\n    # Add Rome with label\n    geom_sf(data = rome_coords, size = 4, color = \"red\", shape = 18) +\n    annotate(\"text\", x = 12.5, y = 41.2, label = \"Rome\", \n             color = \"red\", fontface = \"bold\", size = 3) +\n    # Set map extent\n    coord_sf(xlim = c(study_bbox[\"xmin\"], study_bbox[\"xmax\"]),\n             ylim = c(study_bbox[\"ymin\"], study_bbox[\"ymax\"]),\n             expand = FALSE) +\n    theme_void() +\n    theme(\n      legend.position = \"right\",\n      plot.title = element_text(size = 14, hjust = 0.5),\n      plot.subtitle = element_text(size = 12, hjust = 0.5),\n      panel.background = element_rect(fill = \"lightblue\", color = NA)\n    ) +\n    labs(title = \"Roman Coin Distribution Probability\",\n         subtitle = \"Based on distance decay modeling from Rome\",\n         caption = \"White dots = Coin findspots | Red diamond = Rome\")\n  \n  print(p1_labeled)\n}\n\n\n\n\n\n\n\n# Summary statistics\ncat(\"Analysis Summary:\\n\")\n\nAnalysis Summary:\n\ncat(\"=================\\n\")\n\n=================\n\ncat(\"Total findspots:\", nrow(findspots_sf), \"\\n\")\n\nTotal findspots: 486 \n\ncat(\"Total coins from Rome:\", sum(rome_data$mint_average_count), \"\\n\")\n\nTotal coins from Rome: NA \n\ncat(\"Hexes with data:\", sum(hex_grid$has_findspots, na.rm = TRUE), \"\\n\")\n\nHexes with data: 229 \n\ncat(\"Total hexes:\", nrow(hex_grid), \"\\n\")\n\nTotal hexes: 5000 \n\ncat(\"Max distance to Rome:\", round(max(hex_grid$dist_to_rome), 2), \"km\\n\")\n\nMax distance to Rome: 4372.11 km\n\ncat(\"Min distance to Rome:\", round(min(hex_grid$dist_to_rome), 2), \"km\\n\")\n\nMin distance to Rome: 17.74 km\n\n# Model diagnostics\nif(class(decay_model)[1] == \"nls\") {\n  cat(\"\\nDistance Decay Model (Exponential):\\n\")\n  cat(\"===================================\\n\")\n  print(summary(decay_model))\n} else {\n  cat(\"\\nDistance Decay Model (Linear on log scale):\\n\")\n  cat(\"==========================================\\n\")\n  print(summary(decay_model))\n}\n\n\nDistance Decay Model (Exponential):\n===================================\n\nFormula: total_coins ~ a * exp(-b * dist_to_rome)\n\nParameters:\n   Estimate Std. Error t value Pr(&gt;|t|)    \na 2.013e+03  3.304e+02   6.092 4.72e-09 ***\nb 2.583e-03  4.720e-04   5.473 1.17e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 814.1 on 227 degrees of freedom\n\nNumber of iterations to convergence: 7 \nAchieved convergence tolerance: 9.615e-06\n\n# Create distance vs coins plot\np2 &lt;- ggplot(model_data, aes(x = dist_to_rome, y = total_coins)) +\n  geom_point(alpha = 0.7, size = 2) +\n  geom_smooth(method = \"loess\", se = TRUE, color = \"red\") +\n  scale_y_log10() +\n  labs(title = \"Distance Decay Relationship\",\n       x = \"Distance to Rome (km)\",\n       y = \"Total Coins (log scale)\") +\n  theme_minimal()\n\nprint(p2)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Export results (optional)\n# hex_results &lt;- hex_grid %&gt;%\n#   dplyr::select(hex_id, dist_to_rome, total_coins, predicted_coins, \n#          final_probability, has_findspots) %&gt;%\n#   sf::st_drop_geometry()\n# \n# readr::write_csv(hex_results, \"roman_coin_probability_results.csv\")"
  },
  {
    "objectID": "prepare02.html",
    "href": "prepare02.html",
    "title": "Prepare for Class 02",
    "section": "",
    "text": "NY (2024): 1, 2 (\\(\\cdot\\)), PM (\\(\\cdot\\cdot\\cdot\\))\nNote: \\(\\cdot\\) technical difficulty low; \\(\\cdot\\cdot\\cdot\\) technical difficulty high\n\nCompleted"
  },
  {
    "objectID": "prepare02.html#inge-druckrey",
    "href": "prepare02.html#inge-druckrey",
    "title": "Prepare for Class 02",
    "section": "2.1 Inge Druckrey",
    "text": "2.1 Inge Druckrey\nTeaching to see by Andrei Severny and Edward Tufte (~ 37 minutes)\n\nCompleted\n\n\n2.1.1 Write a one-page review:\n\nLearn thin/thick and curve/linearity from Druckrey\nHow did Holmes describe and contrast the eye and the hand in writing?\nWhy calligraphy is important to Steve Jobs and the design of Mac computers?\nDifferentiate geometric accuracy and optical accuracy\n\nReview: Teaching to See ‚Äì Lessons from Inge Druckrey and Beyond\nIn the documentary Teaching to See, we learned about Inge Druckrey, a design teacher who changed how students look at the world around them. Her teaching method was strict but eye-opening. One of her biggest lessons was about understanding contrasts, the use of negative and positive. Contrasts between thin and thick lines, between curved and straight shapes, and different textures were prominent in her teaching. When students practiced brush lettering and Roman capital letters, they learned how these visual elements work together to create rhythm and balance. Making an ‚ÄòR‚Äô or a ‚ÄòS‚Äô wasn‚Äôt just about making something pretty or functional, it was about mastering the basic contrasts that make letters work and communicate clearly. She pushed students to make small improvements to enhance their work. Make a curve deeper. Adjust a line thickness. She taught them to see the shape, not merely copy it.\nOne student, Holmes, shared an interesting idea about the eye versus the hand in writing. The eye is conservative and wants everything to look neat, orderly, and easy to read. However, the hand is radical, and wants to write fast and show personality. This tension between what the eye wants and what the hand does is the story of handwriting and fonts. The eye demands that we can read something easily, while the hand wants to add personal style. When these two contrasting ideas work together, the world of typography and calligraphy opens up. Holmes‚Äôs comparison captured the main challenge of typography. Follow the rules, but do it expressively and with purpose.\nThis balanced contrast had a huge impact on Steve Jobs. Jobs, known for his design sense, was thoughtfully affected by her tutelage. Jobs said that this class, taken when he was not even a student at Reed, shaped his approach to design. Many years later as he was envisioning the successor to the Apple II, he incorporated advanced computer typography to the interface. The first Macintosh computer included properly spaced fonts and multiple typefaces, which was something completely different from the terminals of the time. Jobs believed that beauty and function should go together, and that computers should have the aesthetic and care found in handwritten letters.\nAn important lessons from her teaching was about the difference between geometric and optical accuracy. Two letters could measure the same size, but they can look different to your eyes. Using a reducing glass, Druckrey would look at student work essentially from far away, spotting visual problems that careful measuring alone couldn‚Äôt find. Students learned that our eyes see weight, proportion, and alignment as a whole, not piece by piece. Design is not about mathematical perfection but about visual truth. She taught students to trust their eyes and keep improving their work until it looked right.\nTeaching to See examined the importance of observing carefully, and working patiently to improve. Students were invited into a lifelong practice of noticing the world around them more clearly and more beautifully."
  },
  {
    "objectID": "prepare02.html#john-glendennings-data-quality-checklist",
    "href": "prepare02.html#john-glendennings-data-quality-checklist",
    "title": "Prepare for Class 02",
    "section": "4.1 John Glendenning‚Äôs Data Quality Checklist",
    "text": "4.1 John Glendenning‚Äôs Data Quality Checklist\nA customized guide for Roman Coinage based on the Quartz Bad Data Guide\n1. Structural Cleanliness\n\nHeaders are correct (no shifted cells, multi-row headers, or misaligned labels)\nEvery column has a consistent type (no mixed datatypes in a single column)\nNo blank rows or columns (especially dangerous in CSVs and spreadsheets)\nNo merged cells (common in XLS/XLSX files‚Äîflatten before use)\nConsistent encoding (UTF-8 preferred for Python/R compatibility)\n\n2. Column-Level Validation\n\nAll dates are parsable and timezone-aware if needed\nString fields are stripped of whitespace (\"Rome \" ‚Üí \"Rome\")\nNo rogue delimiters in text fields (e.g., commas in CSVs without proper quoting)\nNumerical fields are clean (no currency symbols, commas, or locale-specific formatting like 1.000.000)\n\n3. Semantic Accuracy\n\nCheck for mislabeled columns (e.g., latitude/longitude swaps)\nVerify units (e.g., km vs miles, BCE vs CE)\nDecimal vs percentage (e.g., 0.07 vs 7%)\n\n4. Consistency Over Time\n\nHistorical changes tracked (e.g., column schema, CRS, projection systems)\nDecade or time-period tagging consistent (e.g., -90 to -81 BCE)\nAudit trail/logs for any manual cleaning (especially footnote/bibliography removal in PDFs)\n\n5. Missing or Placeholder Data\n\nAll forms of NA/NULL recognized (NA, NaN, null, \"\", -99, etc.)\nMissing values logged by column and count\nDon‚Äôt treat 0 as missing unless contextually appropriate\n\n6. Duplicate Detection\n\nCheck for duplicate rows (especially when scraping or merging)\nCheck for near-duplicates (e.g., Roma, Rome, ROME)\nCheck for duplicate IDs (e.g., coin ID, hoard ID, document IDs)\n\n7. Geospatial Sanity\n\nLatitude between -90 and 90; longitude between -180 and 180\nCRS consistent (e.g., EPSG:3035 for European LAEA)\nNo flipped coordinates (common error: lat/lon reversed)\nHoard and mint points lie on land (not sea) if appropriate\n\n8. Textual Consistency\n\nLigatures and hyphens cleaned (e.g., Ô¨Å ‚Üí fi, eco-\\nnomic ‚Üí economic)\nSpellchecked output, especially OCR text\nEntity redactions logged ([REDACTED_PERSON], etc.)\nBibliographic references stripped only after saving original\n\n9. File-Level Integrity\n\nAvoid Excel-specific features (e.g., macros, pivot tables, styles)\nAll outputs saved in open formats (.csv, .txt, .geojson, .rds)\nFolder names consistent and informative (data/raw/, output/cleaned/)\nFile naming conventions follow: source_var_cleaned_YYYYMMDD.csv\n\n10. Reproducibility and Logging\n\nEvery cleaning step is logged (log_cleaning_YYYY-MM-DD.csv)\nEvery script is version-controlled (e.g., Git, Quarto render logs)\nPipeline can skip existing files\nWarnings and anomalies are caught and reported\n\n11. Statistical Sanity Checks\n\nExpected distribution of values? (e.g., coin counts by year)\nLook for spikes and dips (e.g., all hoards dated -87 BCE?)\nCorrelated fields make sense (e.g., coin start ‚â§ end year)\nGeometric vs optical accuracy assessed for visualizations\n\n12. Common Traps from Quartz Guide\n\nDates as integers in Excel turn into nonsense\nExcel corrupts CSVs with large numbers or 1-1 turning into Jan 1\nInvisible Unicode characters (zero-width space, BOM)\nTrailing commas or missing headers in CSVs\n‚ÄúTotals‚Äù or ‚ÄúNotes‚Äù rows left in"
  },
  {
    "objectID": "prepare02.html#meetings",
    "href": "prepare02.html#meetings",
    "title": "Prepare for Class 02",
    "section": "5.1 Meetings",
    "text": "5.1 Meetings\nSchedule regular meetings to discuss on team project (proposal and presentation due on schedule."
  },
  {
    "objectID": "prepare01.html",
    "href": "prepare01.html",
    "title": "Prepare for Class 01",
    "section": "",
    "text": "Prepare for Class 01\n\nPrepare your own device\n\nComputer on either Windows or MacOS operating system (OS). Tablets are not recommended.\n\n\nCompleted\n\n\nRun the latest update on OS since the computer is your most important companion in this class.\n\n\nCompleted\n\n\nInstall software\n\nProgram/text editor at your choice. The following is only recommended but not required:\n   Visual Studio Code\n\nCompleted - BBEdit, not VSC\n\nR (https://cran.r-project.org)\n   RStudio (https://posit.co/downloads/)\n\nCompleted\n\n\n\n\n=== R VERSION AND PLATFORM ===\n\n\n               _                           \nplatform       aarch64-apple-darwin20      \narch           aarch64                     \nos             darwin20                    \nsystem         aarch64, darwin20           \nstatus                                     \nmajor          4                           \nminor          5.1                         \nyear           2025                        \nmonth          06                          \nday            13                          \nsvn rev        88306                       \nlanguage       R                           \nversion.string R version 4.5.1 (2025-06-13)\nnickname       Great Square Root           \n\n\n\nTeam up\n\nBuild a team of three members\n\nCompleted (Adiline, Elise, John)\n\n\nRead\n\nWilkinson, Leland. 2005. The Grammar of Graphics. Second edition. Springer\n\nCompleted\n\nNext week: Murrell, Paul. 2016. R graphics. CRC Press.\n\nStarted\n\n\nData\n\nIdentify a literature of academic topic and collect data (secondary data will work)\nI am currently working on analyzing Roman coin hoard data in some novel ways. For the initial analysis, data from the Coin Hoards of the Roman Republic was accessed. This dataset is based of the work of Crawford (1969), as enhanced by Gruber and Lockyear.\n\n\nFirst Approach\nThis first approach to the dataset was gathered by downloading data from the web pages.\n\n\n\nFirst 10 Hoards with Rome as Mint\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhoard_id\nhoard_name\nhoard_uri\nhoard_lat\nhoard_lon\nhoard_geometry\nmint_name\nmint_uri\nmint_average_count\nmint_lat\nmint_lon\nmint_geometry\nmint_hoard_distance_km\n\n\n\n\n1PO\nPoiana CrƒÉcƒÉoani (Romania)\nhttps://sws.geonames.org/670093/\n47.06667\n26.31667\nPOINT (26.31667 47.06667)\nRome\nhttp://nomisma.org/id/rome\n123\n41.9\n12.5\nPOINT (12.5 41.9)\n1236.48816\n\n\nABE\nAbertura (Spain)\nhttps://sws.geonames.org/2522486/\n39.24352\n-5.81394\nPOINT (-5.81394 39.24352)\nRome\nhttp://nomisma.org/id/rome\n23\n41.9\n12.5\nPOINT (12.5 41.9)\n1573.37081\n\n\nACT\n√Åktion (Greece)\nhttps://sws.geonames.org/265389/\n38.94019\n20.76875\nPOINT (20.76875 38.94019)\nRome\nhttp://nomisma.org/id/rome\n3\n41.9\n12.5\nPOINT (12.5 41.9)\n773.90425\n\n\nADJ\nAmƒÉrƒÉ≈ütii de Jos (Romania)\nhttps://sws.geonames.org/686386/\n43.95000\n24.16667\nPOINT (24.16667 43.95)\nRome\nhttp://nomisma.org/id/rome\n4\n41.9\n12.5\nPOINT (12.5 41.9)\n977.06559\n\n\nADM\nMassa d‚ÄôAlbe (Italy)\nhttps://sws.geonames.org/3173765/\n42.10723\n13.39429\nPOINT (13.39429 42.10723)\nRome\nhttp://nomisma.org/id/rome\n93\n41.9\n12.5\nPOINT (12.5 41.9)\n77.49022\n\n\nADR\nAlcal√° del R√≠o (Spain)\nhttps://sws.geonames.org/2522474/\n37.51780\n-5.98185\nPOINT (-5.98185 37.5178)\nRome\nhttp://nomisma.org/id/rome\n159\n41.9\n12.5\nPOINT (12.5 41.9)\n1652.39657\n\n\nADU\nAlbanchez de M√°gina (Spain)\nhttps://sws.geonames.org/2522239/\n37.79263\n-3.46833\nPOINT (-3.46833 37.79263)\nRome\nhttp://nomisma.org/id/rome\n16\n41.9\n12.5\nPOINT (12.5 41.9)\n1436.74096\n\n\nAGG\nAggius (Italy)\nhttps://sws.geonames.org/3183443/\n40.92995\n9.06517\nPOINT (9.06517 40.92995)\nRome\nhttp://nomisma.org/id/rome\n10\n41.9\n12.5\nPOINT (12.5 41.9)\n306.37972\n\n\nAGN\nAgnona (Italy)\nhttps://sws.geonames.org/6693917/\n45.72602\n8.25957\nPOINT (8.25957 45.72602)\nRome\nhttp://nomisma.org/id/rome\n244\n41.9\n12.5\nPOINT (12.5 41.9)\n545.19648\n\n\nAID\nAid√≥na (Greece)\nhttps://sws.geonames.org/265542/\n39.60542\n21.46797\nPOINT (21.46797 39.60542)\nRome\nhttp://nomisma.org/id/rome\n4\n41.9\n12.5\nPOINT (12.5 41.9)\n797.75946\n\n\n\n\n\nSecond Approach\nThe second method used the following SPARQL query through the Nomisma SPARQL endpoint. The SPARQL code is can be accessed above.\n\n\n\nFirst 10 Coins in Hoards with Rome as Mint, Method 2\n\n\nhoard\nhoardID\ntype\ntypeLabel\nstartYear\nendYear\ndenomination\ndenominationLabel\nmaterial\nmaterialLabel\nmint\nmintID\nhoardLat\nhoardLong\nmintLat\nmintLong\n\n\n\n\nhttp://numismatics.org/chrr/id/1PO\n1PO\nhttp://numismatics.org/crro/id/rrc-187.1\n‚ÄúRRC 187/1‚Äù@en\n-169\n-158\nhttp://nomisma.org/id/denarius\n‚ÄúDenarius‚Äù@en\nhttp://nomisma.org/id/ar\n‚ÄúSilver‚Äù@en\nhttp://nomisma.org/id/rome\nrome\n47.06903\n26.30626\n41.9\n12.5\n\n\nhttp://numismatics.org/chrr/id/1PO\n1PO\nhttp://numismatics.org/crro/id/rrc-200.1\n‚ÄúRRC 200/1‚Äù@en\n-155\n-155\nhttp://nomisma.org/id/denarius\n‚ÄúDenarius‚Äù@en\nhttp://nomisma.org/id/ar\n‚ÄúSilver‚Äù@en\nhttp://nomisma.org/id/rome\nrome\n47.06903\n26.30626\n41.9\n12.5\n\n\nhttp://numismatics.org/chrr/id/1PO\n1PO\nhttp://numismatics.org/crro/id/rrc-216.1\n‚ÄúRRC 216/1‚Äù@en\n-148\n-148\nhttp://nomisma.org/id/denarius\n‚ÄúDenarius‚Äù@en\nhttp://nomisma.org/id/ar\n‚ÄúSilver‚Äù@en\nhttp://nomisma.org/id/rome\nrome\n47.06903\n26.30626\n41.9\n12.5\n\n\nhttp://numismatics.org/chrr/id/1PO\n1PO\nhttp://numismatics.org/crro/id/rrc-228.2\n‚ÄúRRC 228/2‚Äù@en\n-140\n-140\nhttp://nomisma.org/id/denarius\n‚ÄúDenarius‚Äù@en\nhttp://nomisma.org/id/ar\n‚ÄúSilver‚Äù@en\nhttp://nomisma.org/id/rome\nrome\n47.06903\n26.30626\n41.9\n12.5\n\n\nhttp://numismatics.org/chrr/id/1PO\n1PO\nhttp://numismatics.org/crro/id/rrc-231.1\n‚ÄúRRC 231/1‚Äù@en\n-138\n-138\nhttp://nomisma.org/id/denarius\n‚ÄúDenarius‚Äù@en\nhttp://nomisma.org/id/ar\n‚ÄúSilver‚Äù@en\nhttp://nomisma.org/id/rome\nrome\n47.06903\n26.30626\n41.9\n12.5\n\n\nhttp://numismatics.org/chrr/id/1PO\n1PO\nhttp://numismatics.org/crro/id/rrc-233.1\n‚ÄúRRC 233/1‚Äù@en\n-138\n-138\nhttp://nomisma.org/id/denarius\n‚ÄúDenarius‚Äù@en\nhttp://nomisma.org/id/ar\n‚ÄúSilver‚Äù@en\nhttp://nomisma.org/id/rome\nrome\n47.06903\n26.30626\n41.9\n12.5\n\n\nhttp://numismatics.org/chrr/id/1PO\n1PO\nhttp://numismatics.org/crro/id/rrc-237.1a\n‚ÄúRRC 237/1a‚Äù@en\n-136\n-136\nhttp://nomisma.org/id/denarius\n‚ÄúDenarius‚Äù@en\nhttp://nomisma.org/id/ar\n‚ÄúSilver‚Äù@en\nhttp://nomisma.org/id/rome\nrome\n47.06903\n26.30626\n41.9\n12.5\n\n\nhttp://numismatics.org/chrr/id/1PO\n1PO\nhttp://numismatics.org/crro/id/rrc-244.1\n‚ÄúRRC 244/1‚Äù@en\n-134\n-134\nhttp://nomisma.org/id/denarius\n‚ÄúDenarius‚Äù@en\nhttp://nomisma.org/id/ar\n‚ÄúSilver‚Äù@en\nhttp://nomisma.org/id/rome\nrome\n47.06903\n26.30626\n41.9\n12.5\n\n\nhttp://numismatics.org/chrr/id/1PO\n1PO\nhttp://numismatics.org/crro/id/rrc-245.1\n‚ÄúRRC 245/1‚Äù@en\n-134\n-134\nhttp://nomisma.org/id/denarius\n‚ÄúDenarius‚Äù@en\nhttp://nomisma.org/id/ar\n‚ÄúSilver‚Äù@en\nhttp://nomisma.org/id/rome\nrome\n47.06903\n26.30626\n41.9\n12.5\n\n\nhttp://numismatics.org/chrr/id/1PO\n1PO\nhttp://numismatics.org/crro/id/rrc-250.1\n‚ÄúRRC 250/1‚Äù@en\n-132\n-132\nhttp://nomisma.org/id/denarius\n‚ÄúDenarius‚Äù@en\nhttp://nomisma.org/id/ar\n‚ÄúSilver‚Äù@en\nhttp://nomisma.org/id/rome\nrome\n47.06903\n26.30626\n41.9\n12.5\n\n\n\n\n\n\nCollect charts from studies\n\nSome charts based on the data from the CHRR data.\n      \n\nDiscussion for next week:\n\nWhat is the difference between graphics and:\n\nmusical notes\nGraphics are primarily spatial and visual, representing information through location, shape, color, and other visual relationships. Musical notes, which are visual on paper, are based on auditory waveforms over time. Graphics can be processed visually and interpreted nearly instantly as a whole, while music is interpreted sequentially over time to create meaning.\nverbal language\nGraphics communicate through direct visual representation and spatial relationships, showing rather than telling. Verbal language uses symbolic abstraction. Arbitrary words and grammatical structures which require learning conventions to decode meaning. Graphics can transcend spoken language barriers and can often convey complex spatial or quantitative relationships more efficiently than words. Verbal language excels at expressing abstract concepts, logical arguments, and narrative sequences that would be difficult to represent visually in graphics.\nmathematical notations\nBoth graphics and mathematical notation may represent quantitative relationships, but they do so differently. Graphics present information through visual metaphors and relationships suah as showing data through bar heights or trend lines. Mathematical notation uses precise symbolic logic with specific meanings to represent these quantitative relationships. A graph might show that one value is much different than another, while mathematical notation can specify exactly how much different. Graphics also can create a more emotional connnection to the information than mathematics, which is one way that graphics can be more manipulative than mathematics. Mathematical notation is also more compact and precise for complex calculations, while graphics make patterns and relationships more immediately apparent to human visual perception.\n\nHow many ways messages can be conveyed?\nAny way that humans can perceive is a way that we can convey a message. Some are more efficient than others. Some are task-specific. We can categorize these, roughly:\n\nVisual: text, images, graphics, gestures, facial expressions, sign language, light signals\nAuditory: speech, music, sounds, tones\nTactile: touch, braille, vibrations, textures\nOlfactory: scents, pheromones (not a concious choice but worth noting)\nGustatory: taste (very limited uses, though)\n\nDifferent methods of communication serve different purposes, prioritizing different things such as speed, accuracy, distance, etc.\n\n\n\n\nBibliography\nCrawford, Michael H. 1974. Roman Republican Coinage. 2 vols. Cambridge: Cambridge University Press."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "John Glendenning",
    "section": "",
    "text": "I am a masters student studying geographical information systems.\n\nContact\njmg220005@utdallas.edu"
  },
  {
    "objectID": "Work.html",
    "href": "Work.html",
    "title": "Work",
    "section": "",
    "text": "Work samples will go here.\n\n\n\nPrincess Donut"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "git_blog",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nSep 23, 2025\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nSep 20, 2025\n\n\nTristan O‚ÄôMalley\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Post\n\n\n\n\n\n\nQuarto\n\n\nR\n\n\n\nLet‚Äôs see if this works.\n\n\n\n\n\nAug 18, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2025-08-18-First-Post/index.html",
    "href": "posts/2025-08-18-First-Post/index.html",
    "title": "First Post",
    "section": "",
    "text": "Maybe I should put the something useful here."
  },
  {
    "objectID": "assignment01.html",
    "href": "assignment01.html",
    "title": "Assignment 01",
    "section": "",
    "text": "Ground rules: All assigned works are to be published on own GitHub website/blog."
  },
  {
    "objectID": "assignment01.html#revisit-anscombes-examples-anscombe01.r-on-teams",
    "href": "assignment01.html#revisit-anscombes-examples-anscombe01.r-on-teams",
    "title": "Assignment 01",
    "section": "1 Revisit Anscombe‚Äôs examples (anscombe01.R on Teams)",
    "text": "1 Revisit Anscombe‚Äôs examples (anscombe01.R on Teams)\n\n## Data Visualization\n## Objective: Identify data or model problems using visualization\n## Anscombe (1973) Quartlet\n\ndata(anscombe)  # Load Anscombe's data\nanscombe\n\n   x1 x2 x3 x4    y1   y2    y3    y4\n1  10 10 10  8  8.04 9.14  7.46  6.58\n2   8  8  8  8  6.95 8.14  6.77  5.76\n3  13 13 13  8  7.58 8.74 12.74  7.71\n4   9  9  9  8  8.81 8.77  7.11  8.84\n5  11 11 11  8  8.33 9.26  7.81  8.47\n6  14 14 14  8  9.96 8.10  8.84  7.04\n7   6  6  6  8  7.24 6.13  6.08  5.25\n8   4  4  4 19  4.26 3.10  5.39 12.50\n9  12 12 12  8 10.84 9.13  8.15  5.56\n10  7  7  7  8  4.82 7.26  6.42  7.91\n11  5  5  5  8  5.68 4.74  5.73  6.89\n\n#View(anscombe) # View the data\nsummary(anscombe)\n\n       x1             x2             x3             x4           y1        \n Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  \n 1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  \n Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  \n Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  \n 3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  \n Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  \n       y2              y3              y4        \n Min.   :3.100   Min.   : 5.39   Min.   : 5.250  \n 1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  \n Median :8.140   Median : 7.11   Median : 7.040  \n Mean   :7.501   Mean   : 7.50   Mean   : 7.501  \n 3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  \n Max.   :9.260   Max.   :12.74   Max.   :12.500  \n\n## Simple version\nplot(anscombe$x1,anscombe$y1)\nsummary(anscombe)\n\n       x1             x2             x3             x4           y1        \n Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  \n 1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  \n Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  \n Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  \n 3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  \n Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  \n       y2              y3              y4        \n Min.   :3.100   Min.   : 5.39   Min.   : 5.250  \n 1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  \n Median :8.140   Median : 7.11   Median : 7.040  \n Mean   :7.501   Mean   : 7.50   Mean   : 7.501  \n 3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  \n Max.   :9.260   Max.   :12.74   Max.   :12.500  \n\n# Create four model objects\nlm1 &lt;- lm(y1 ~ x1, data=anscombe)\nsummary(lm1)\n\n\nCall:\nlm(formula = y1 ~ x1, data = anscombe)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.92127 -0.45577 -0.04136  0.70941  1.83882 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0001     1.1247   2.667  0.02573 * \nx1            0.5001     0.1179   4.241  0.00217 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6665,    Adjusted R-squared:  0.6295 \nF-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\n\nlm2 &lt;- lm(y2 ~ x2, data=anscombe)\nsummary(lm2)\n\n\nCall:\nlm(formula = y2 ~ x2, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9009 -0.7609  0.1291  0.9491  1.2691 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)    3.001      1.125   2.667  0.02576 * \nx2             0.500      0.118   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6662,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\n\nlm3 &lt;- lm(y3 ~ x3, data=anscombe)\nsummary(lm3)\n\n\nCall:\nlm(formula = y3 ~ x3, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.1586 -0.6146 -0.2303  0.1540  3.2411 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0025     1.1245   2.670  0.02562 * \nx3            0.4997     0.1179   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6663,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\n\nlm4 &lt;- lm(y4 ~ x4, data=anscombe)\nsummary(lm4)\n\n\nCall:\nlm(formula = y4 ~ x4, data = anscombe)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.751 -0.831  0.000  0.809  1.839 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0017     1.1239   2.671  0.02559 * \nx4            0.4999     0.1178   4.243  0.00216 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6667,    Adjusted R-squared:  0.6297 \nF-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\nplot(anscombe$x1,anscombe$y1)\nabline(coefficients(lm1))\n\n\n\n\n\n\n\nplot(anscombe$x2,anscombe$y2)\nabline(coefficients(lm2))\n\n\n\n\n\n\n\nplot(anscombe$x3,anscombe$y3)\nabline(coefficients(lm3))\n\n\n\n\n\n\n\nplot(anscombe$x4,anscombe$y4)\nabline(coefficients(lm4))\n\n\n\n\n\n\n\n## Fancy version (per help file)\n\nff &lt;- y ~ x\nmods &lt;- setNames(as.list(1:4), paste0(\"lm\", 1:4))\n\n# Plot using for loop\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  ## or   ff[[2]] &lt;- as.name(paste0(\"y\", i))\n  ##      ff[[3]] &lt;- as.name(paste0(\"x\", i))\n  mods[[i]] &lt;- lmi &lt;- lm(ff, data = anscombe)\n  print(anova(lmi))\n}\n\nAnalysis of Variance Table\n\nResponse: y1\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nx1         1 27.510 27.5100   17.99 0.00217 **\nResiduals  9 13.763  1.5292                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y2\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx2         1 27.500 27.5000  17.966 0.002179 **\nResiduals  9 13.776  1.5307                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y3\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx3         1 27.470 27.4700  17.972 0.002176 **\nResiduals  9 13.756  1.5285                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y4\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx4         1 27.490 27.4900  18.003 0.002165 **\nResiduals  9 13.742  1.5269                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsapply(mods, coef)  # Note the use of this function\n\n                  lm1      lm2       lm3       lm4\n(Intercept) 3.0000909 3.000909 3.0024545 3.0017273\nx1          0.5000909 0.500000 0.4997273 0.4999091\n\nlapply(mods, function(fm) coef(summary(fm)))\n\n$lm1\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0000909  1.1247468 2.667348 0.025734051\nx1          0.5000909  0.1179055 4.241455 0.002169629\n\n$lm2\n            Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.000909  1.1253024 2.666758 0.025758941\nx2          0.500000  0.1179637 4.238590 0.002178816\n\n$lm3\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0024545  1.1244812 2.670080 0.025619109\nx3          0.4997273  0.1178777 4.239372 0.002176305\n\n$lm4\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0017273  1.1239211 2.670763 0.025590425\nx4          0.4999091  0.1178189 4.243028 0.002164602\n\n# Preparing for the plots\nop &lt;- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0))\n\n# Plot charts using for loop\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"red\", pch = 21, bg = \"orange\", cex = 1.2,\n       xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"blue\")\n}\nmtext(\"Anscombe's 4 Regression data sets\", outer = TRUE, cex = 1.5)\n\n\n\n\n\n\n\npar(op)\n\n\n1.1 Read: Anscombe, Francis J. 1973.‚ÄùGraphs in statistical analysis.‚Äù The American Statistician 27, no. 1: 17-21.\n\nCompleted\n\n\n\n1.2 Write one paragraph to analyze and suggest solutions.\nIn the paper Graphs in Statistical Analysis (Anscombe 1973), it is demonstrated that visual inspection of data is essential to the process of analysis. With four datasets, now commonly referred to as the Anscombe Quartet, it is demonstrated that four divergent datasets can have the same statistical properties, but be very different in their structure. The underlying issue was that relying solely on summary data can obfuscate the underlying data features like non-linearity, outliers or other influential points. Anscombe demonstrated the need for residual plots and scatterplots to detect deviations from the underlying model assumptions, such as heteroscedasticity. To address these types of problems, graphic diagnostics should be integrated as a routine component of statistical analysis, especially in a regression or mulivariate analysis."
  },
  {
    "objectID": "assignment01.html#run-fall.r-on-teams",
    "href": "assignment01.html#run-fall.r-on-teams",
    "title": "Assignment 01",
    "section": "2 Run Fall.R (on Teams)",
    "text": "2 Run Fall.R (on Teams)\n\n2.1 Give your own colors (e.g.¬†Winter).\nColor: steelblue, output below\n\n\n2.2 Export the file and post on your GitHub website.\nThis is the file.\nSee below.\n\n2.2.1 Single Color\n\n# Title Fall color\n# Credit: https://fronkonstin.com\n\n# Install packages\n\n# install.packages(\"gsubfn\")\n# install.packages(\"tidyverse\")\nlibrary(gsubfn)\n\nLoading required package: proto\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.2\n‚úî ggplot2   4.0.0     ‚úî tibble    3.3.0\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.1\n‚úî purrr     1.1.0     \n\n\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Define elements in plant art\n# Each image corresponds to a different axiom, rules, angle and depth\n\n# Leaf of Fall\n\naxiom=\"X\"\nrules=list(\"X\"=\"F-[[X]+X]+F[+FX]-X\", \"F\"=\"FF\")\nangle=22.5\ndepth=6\n\n\nfor (i in 1:depth) axiom=gsubfn(\".\", rules, axiom)\n\nactions=str_extract_all(axiom, \"\\\\d*\\\\+|\\\\d*\\\\-|F|L|R|\\\\[|\\\\]|\\\\|\") %&gt;% unlist\n\nstatus=data.frame(x=numeric(0), y=numeric(0), alfa=numeric(0))\npoints=data.frame(x1 = 0, y1 = 0, x2 = NA, y2 = NA, alfa=90, depth=1)\n\n\n# Generating data\n# Note: may take a minute or two\n\nfor (action in actions)\n{\n  if (action==\"F\")\n  {\n    x=points[1, \"x1\"]+cos(points[1, \"alfa\"]*(pi/180))\n    y=points[1, \"y1\"]+sin(points[1, \"alfa\"]*(pi/180))\n    points[1,\"x2\"]=x\n    points[1,\"y2\"]=y\n    data.frame(x1 = x, y1 = y, x2 = NA, y2 = NA,\n               alfa=points[1, \"alfa\"],\n               depth=points[1,\"depth\"]) %&gt;% rbind(points)-&gt;points\n  }\n  if (action %in% c(\"+\", \"-\")){\n    alfa=points[1, \"alfa\"]\n    points[1, \"alfa\"]=eval(parse(text=paste0(\"alfa\",action, angle)))\n  }\n  if(action==\"[\"){\n    data.frame(x=points[1, \"x1\"], y=points[1, \"y1\"], alfa=points[1, \"alfa\"]) %&gt;%\n      rbind(status) -&gt; status\n    points[1, \"depth\"]=points[1, \"depth\"]+1\n  }\n\n  if(action==\"]\"){\n    depth=points[1, \"depth\"]\n    points[-1,]-&gt;points\n    data.frame(x1=status[1, \"x\"], y1=status[1, \"y\"], x2=NA, y2=NA,\n               alfa=status[1, \"alfa\"],\n               depth=depth-1) %&gt;%\n      rbind(points) -&gt; points\n    status[-1,]-&gt;status\n  }\n}\n\nggplot() +\n  geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2),\n               lineend = \"round\",\n               color=\"steelblue\", # Set your own Fall color?\n               data=na.omit(points)) +\n  coord_fixed(ratio = 1) +\n  theme_void() # No grid nor axes\n\n\n\n\n\n\n\n\n\n\n2.2.2 More Fall Colors\n\nfall_colors &lt;- c(\"darkorange\", \"goldenrod\", \"firebrick\", \"sienna\", \"chocolate\")\npoints_clean &lt;- na.omit(points)\n\n# Create a separate plot for each color\nfor (color in fall_colors) {\n  # Add color column with current color for all segments\n  points_clean$current_color &lt;- color\n  \n  p &lt;- ggplot(points_clean) + \n    geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), \n                 color = color, lineend = \"round\") +\n    coord_fixed(ratio = 1) + \n    theme_void() +\n    ggtitle(paste(\"Plot with color:\", color))\n  \n  print(p)\n}"
  },
  {
    "objectID": "assignment01.html#write-a-critique-on-a-chart-in-published-work-bookarticlenews-website",
    "href": "assignment01.html#write-a-critique-on-a-chart-in-published-work-bookarticlenews-website",
    "title": "Assignment 01",
    "section": "3 Write a critique on a chart in published work (book/article/news website)",
    "text": "3 Write a critique on a chart in published work (book/article/news website)\n(Hint: Learn from Nathan Yau‚Äôs example discussed in class). Post on your website.\n\n\n\nFigure 01\n\n\nCritique of a Graph\nThe chart (Fig 01) shows the cumulative percentage over time (210‚Äì30 BCE) across four coin hoards. While it provides a useful comparison of coins over time, it falls short in several ways, and could be made easier to read while being graphically more rich.\nTopic\n\nProblem: The chart does not clearly state what is being accumulated. From the context of the article, it should be apparent, but as a stand alone chart, it is not.\n\nSolution: Add a more precise title and subtitle that clarify the subject of the chart.\n\nProblem: What are the sizes of each hoard. It is not clear how many coins are in each hoard or in each epoch.\n\nSolution: Some method of tracking relative sizes with gradient shading or dot size.\nMessage and Narrative\n\nProblem: The visual comparison between sites is good, but no guidance is provided for interpreting these patterns. For instance, Actium‚Äôs rise is extremely late, and HEN shows a sharp increase around 130‚Äì100 BCE. These are visually significant but go unmarked.\n\nSolution: Use annotations, callouts, or direct labeling to highlight key inflection points and guide the viewer‚Äôs attention to what matters. Tying in historical dates into the timeline will give the reader more connection to the data.\nVisual Encoding and Labeling\n\nProblem: Label is unhelpful and hard to read.\n\nSolution: Move it to the side of the graph, delineate each hoard better, and better show color and shape of each.\n\nProblem: Lines are hard read quickly.\n\nSolution: Change the color palette to something that is easier to read. Vary the line styles. Change the point shape or size.\n\nProblem: The graphs text are hard to read.\n\nSolution: Change font, weight, kerning, or any other parameter to be more legible\nGeography\n\nProblem: Are these hoards located near each other or far? The geographic interrelationship is unknown.\n\nSolution: Add a very tiny map in some of the blank space of the chart. Extend the y-axis if more room is needed.\nAxis and Scale Choices\n\nProblem: Axis labels start with odd numbers. Usually it is quicker and easier to conceptualize dates that start with even numbers.\n\nSolution: Change the labels."
  },
  {
    "objectID": "assignment01.html#bibliography",
    "href": "assignment01.html#bibliography",
    "title": "Assignment 01",
    "section": "4 Bibliography",
    "text": "4 Bibliography\nAnscombe, F. J. (1973). Graphs in Statistical Analysis. The American Statistician, 27(1), 17‚Äì21. https://doi.org/10.1080/00031305.1973.10478966"
  },
  {
    "objectID": "SPARQL.html",
    "href": "SPARQL.html",
    "title": "SPARQL",
    "section": "",
    "text": "Nomisma SPARQL Endpoint"
  },
  {
    "objectID": "SPARQL.html#example-1",
    "href": "SPARQL.html#example-1",
    "title": "SPARQL",
    "section": "Example 1",
    "text": "Example 1\nModified from R networks analysis / works\nSELECT DISTINCT ?hoard ?mint ?mintlat ?mintlong WHERE {\n{\n  ?hoard void:inDataset &lt;http://numismatics.org/chrr/&gt; ;\n  dcterms:tableOfContents/nmo:hasTypeSeriesItem/nmo:hasMint ?mint .\n}\nUNION\n{ ?hoard a nmo:Hoard ;\ndcterms:tableOfContents [ nmo:hasTypeSeriesItem ?tsi ] .\n?tsi nmo:hasMint ?mint .\n}\nOPTIONAL { ?hoard nmo:hasFindspot [\ngeo:lat ?hoardlat ;\ngeo:long ?hoardlong ] }\nOPTIONAL { ?mint geo:location [\ngeo:lat ?mintlat ;\ngeo:long ?mintlong ] }\n}"
  },
  {
    "objectID": "SPARQL.html#example-2",
    "href": "SPARQL.html#example-2",
    "title": "SPARQL",
    "section": "Example 2",
    "text": "Example 2\nPREFIX crm:   &lt;http://www.cidoc-crm.org/cidoc-crm/&gt;\nPREFIX dcterms:&lt;http://purl.org/dc/terms/&gt;\nPREFIX foaf:  &lt;http://xmlns.com/foaf/0.1/&gt;\nPREFIX geo:   &lt;http://www.w3.org/2003/01/geo/wgs84_pos#&gt;\nPREFIX nm:    &lt;http://nomisma.org/id/&gt;\nPREFIX nmo:   &lt;http://nomisma.org/ontology#&gt;\nPREFIX rdfs:  &lt;http://www.w3.org/2000/01/rdf-schema#&gt;\nPREFIX skos:  &lt;http://www.w3.org/2004/02/skos/core#&gt;\n\nSELECT DISTINCT\n  ?hoard ?hoardID\n  ?type (COALESCE(?tlabel, ?plabel, ?rlabel, ?flabel) AS ?typeLabel)\n  (STR(?startDate) AS ?startYear)\n  (STR(?endDate)   AS ?endYear)\n  ?denomination ?denominationLabel\n  ?material     ?materialLabel\n  ?mint ?mintID\n  ?hoardLat ?hoardLong\n  ?mintLat  ?mintLong\nWHERE {\n  # --- All CHRR hoards and their contents ---\n  ?hoard a nmo:Hoard ;\n         dcterms:tableOfContents ?contents .\n  FILTER(STRSTARTS(STR(?hoard), \"http://numismatics.org/chrr/id/\"))\n  BIND(REPLACE(STR(?hoard), \"http://numismatics.org/chrr/id/\", \"\") AS ?hoardID)\n\n  # --- Mint (via type-series item or directly on contents) ---\n  {\n    ?contents nmo:hasTypeSeriesItem ?type .\n    ?type     nmo:hasMint ?mint .\n  }\n  UNION\n  {\n    ?contents nmo:hasMint ?mint .\n    OPTIONAL { ?contents nmo:hasTypeSeriesItem ?type }\n  }\n  BIND(REPLACE(STR(?mint), \"http://nomisma.org/id/\", \"\") AS ?mintID)\n\n  # --- Type labels & dates (from CRRO type, when present) ---\n  OPTIONAL { ?type dcterms:title    ?tlabel  FILTER(LANG(?tlabel)  = \"\" || LANGMATCHES(LANG(?tlabel),  \"en\")) }\n  OPTIONAL { ?type skos:prefLabel   ?plabel  FILTER(LANG(?plabel) = \"\" || LANGMATCHES(LANG(?plabel), \"en\")) }\n  OPTIONAL { ?type rdfs:label       ?rlabel  FILTER(LANG(?rlabel)  = \"\" || LANGMATCHES(LANG(?rlabel),  \"en\")) }\n  OPTIONAL { ?type foaf:name        ?flabel  FILTER(LANG(?flabel)  = \"\" || LANGMATCHES(LANG(?flabel),  \"en\")) }\n\n  OPTIONAL { ?type nmo:hasStartDate ?startDate }\n  OPTIONAL { ?type nmo:hasEndDate   ?endDate }\n\n  # --- Denomination & material (from type) ---\n  OPTIONAL {\n    ?type nmo:hasDenomination ?denomination .\n    OPTIONAL {\n      ?denomination (skos:prefLabel|rdfs:label|foaf:name) ?denominationLabel .\n      FILTER(LANG(?denominationLabel) = \"\" || LANGMATCHES(LANG(?denominationLabel), \"en\"))\n    }\n  }\n  OPTIONAL {\n    ?type nmo:hasMaterial ?material .\n    OPTIONAL {\n      ?material (skos:prefLabel|rdfs:label|foaf:name) ?materialLabel .\n      FILTER(LANG(?materialLabel) = \"\" || LANGMATCHES(LANG(?materialLabel), \"en\"))\n    }\n  }\n\n  # --- Mint geolocation (Nomisma places) ---\n  OPTIONAL {\n    { ?mint geo:location [ geo:lat ?mintLat ;  geo:long ?mintLong ] }\n    UNION\n    { ?mint geo:lat ?mintLat . ?mint geo:long ?mintLong }\n  }\n\n  # --- Hoard geolocation (several fallbacks common in CHRR) ---\n  OPTIONAL {\n    # A) Direct findspot place with geo\n    { ?hoard nmo:hasFindspot ?hPlace .\n      { ?hPlace geo:location [ geo:lat ?hoardLat ; geo:long ?hoardLong ] }\n      UNION\n      { ?hPlace geo:lat ?hoardLat . ?hPlace geo:long ?hoardLong }\n    }\n    UNION\n    # B) CRM region chain with geo\n    {\n      ?hoard nmo:hasFindspot [\n        crm:P7_took_place_at [\n          crm:P89_falls_within ?region\n        ]\n      ] .\n      ?region geo:location ?spatialThing .\n      ?spatialThing geo:lat ?hoardLat ; geo:long ?hoardLong .\n    }\n    UNION\n    # C) dcterms:spatial to a place with geo\n    {\n      ?hoard dcterms:spatial ?hPlace2 .\n      { ?hPlace2 geo:location [ geo:lat ?hoardLat ; geo:long ?hoardLong ] }\n      UNION\n      { ?hPlace2 geo:lat ?hoardLat . ?hPlace2 geo:long ?hoardLong }\n    }\n  }\n}\nORDER BY ?hoardID ?typeLabel ?type ?mint"
  },
  {
    "objectID": "SPARQL.html#mint-data-only",
    "href": "SPARQL.html#mint-data-only",
    "title": "SPARQL",
    "section": "Mint Data Only",
    "text": "Mint Data Only"
  },
  {
    "objectID": "SPARQL.html#coins-in-hoard",
    "href": "SPARQL.html#coins-in-hoard",
    "title": "SPARQL",
    "section": "Coins in Hoard",
    "text": "Coins in Hoard"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a Master‚Äôs student at the University of Texas at Dallas studying GIS.\nI am interested in applying GIS tools and techniques to historical questions. Projects that I have worked on include:\n\nRoman villa site location analysis and predictive modeling\nA Python implementation of Geomorphons\nApplication of low-cost drones to disaster efforts\nPython-based DEM-based spatial statistics via WCS data-acquisition\n\nI am currently working on analyzing Roman coin hoards.\nI have a strong interest in remote sensing and tools.\nCurriculum vitae"
  },
  {
    "objectID": "prepare03.html",
    "href": "prepare03.html",
    "title": "Prepare for Class 03",
    "section": "",
    "text": "Completed\n\nIn the pull down menu above."
  },
  {
    "objectID": "prepare03.html#mcghee-geoff.-2011.",
    "href": "prepare03.html#mcghee-geoff.-2011.",
    "title": "Prepare for Class 03",
    "section": "3.1 McGhee, Geoff. 2011.",
    "text": "3.1 McGhee, Geoff. 2011.\nJournalism in the Age of Data, available at Stanford website.\n\nCompleted\n\n\nWrite a one page review comparing journalistic data visualization and academic data visualization\n\nComparing Journalistic and Academic Data Visualization\nThe landscape of data visualization has expanded rapidly, but two dominant modes‚Äîjournalistic and academic‚Äîillustrate divergent goals, aesthetics, and methodologies. Both serve the essential function of communicating complex data to human audiences, but they differ sharply in how they define success.\nAcademic visualizations emphasize exploration, rigor, and precision. As Martin Wattenberg of IBM notes, visualization is most effective when it‚Äôs treated as both art and writing‚Äînot just a programming task. In academic contexts, visualizations are often designed to reveal patterns, support hypothesis generation, or offer granular, high-dimensional data explorations, typically for an expert audience. Tools like Many Eyes, Protovis, or Flare reflect this ethos: democratizing access while preserving analytical depth. However, these tools often come with steeper learning curves and require knowledge of statistics, programming, and domain-specific theory. The ideal output here is less about beauty and more about insight, even at the cost of complexity or abstraction.\nJournalistic visualizations, on the other hand, aim to inform, persuade, or emotionally resonate with a general audience. They prioritize narrative clarity, accessibility, and aesthetic engagement. Amanda Cox of The New York Times exemplifies this approach with her ‚Äúporcupine chart‚Äù on federal deficit projections, where visual storytelling clarified complex economic data in seconds. Newsrooms now integrate statisticians, GIS experts, and interface designers, focusing on quick-turnaround visuals that must function under tight editorial deadlines. As noted by Sarah Slobin and others, journalistic visuals must ‚Äúgrab attention within four seconds,‚Äù and often adopt slideshow, martini-glass, or drill-down formats to layer depth without overwhelming users.\nYet, challenges remain on both sides. Journalistic visualizations often sacrifice nuance for clarity, potentially leading to shallow or misleading interpretations. Conversely, academic visuals may alienate non-experts by lacking guidance, interactivity, or visual appeal. As Nigel Holmes warns, beautiful but incomprehensible visuals are just as dangerous as poorly written stories.\nThe future likely lies in hybrid approaches. Projects like CrimeSpotting, or the Crisis of Credit video, exemplify a fusion of academic depth and journalistic clarity, blending narrative, interactivity, and motion graphics. As Google‚Äôs public data tools and open data initiatives proliferate, both academics and journalists must adapt‚Äîreimagining their roles not just as analysts or storytellers, but as designers of discovery experiences.\nIn short, academic visualizations illuminate, journalistic ones communicate. The best visualizations do both."
  },
  {
    "objectID": "prepare03.html#isabella-vel√°squez.",
    "href": "prepare03.html#isabella-vel√°squez.",
    "title": "Prepare for Class 03",
    "section": "3.2 Isabella Vel√°squez.",
    "text": "3.2 Isabella Vel√°squez.\nBuilding a Blog with Quarto (YouTube link)\n\nPosit: Creating a Blog\n\nChoose RStudio method\nPublish to GitHub Pages\n\n\n\nCompleted"
  },
  {
    "objectID": "project02.html",
    "href": "project02.html",
    "title": "Project - Proposal",
    "section": "",
    "text": "\\(\\textbf{Differentiation}\\\\\\)\n\\\n\\ $\nIn-line \\[\\begin{align*}\nP(\\text{not } A) &= 1 - P(A) \\\\\nP(A \\text{ and } B) &= P(A) \\times P(B)\n\\end{align*}\\]\nSide-by-side\n\\[\\begin{array}{ll}\nP(\\text{not } A) = 1 - P(A) &\nP(A \\text{ and } B) = P(A) \\times P(B)\n\\end{array}\\]\n\\(\\textbf{Statistics}\\)\n\nThis is a simple LaTeX document that demonstrates how to write mathematical equations.\nHere is an inline equation: \\(E = mc^2\\), which shows the relationship between energy, mass, and the speed of light. $$ Here is the same equation as a displayed equation:\nE = mc^2\n$$\n\n\nTo make the visualizations sophisticated, artistic, and attractive: - Use custom color palettes (viridis, wesanderson, scientific palettes).\n- Explore non-traditional layouts (circular, radial, layered).\n- Add interactive storytelling: clicking on a region brings up linked health/education/voting histories."
  },
  {
    "objectID": "project02.html#additions",
    "href": "project02.html#additions",
    "title": "Project - Proposal",
    "section": "",
    "text": "To make the visualizations sophisticated, artistic, and attractive: - Use custom color palettes (viridis, wesanderson, scientific palettes).\n- Explore non-traditional layouts (circular, radial, layered).\n- Add interactive storytelling: clicking on a region brings up linked health/education/voting histories."
  }
]