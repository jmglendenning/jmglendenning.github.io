---
title: "Project - Brainstorming"
author: "John Glendenning"
output: 
  html:
    documentclass: "article"
    options: [fleqn]
    math: latex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Set CRAN mirror (using RStudio's mirror as an example)
options(repos = c(CRAN = "https://cran.rstudio.com/"))

# List of required packages
packages <- c("devtools", "dplyr", "ggplot2", "readr", "tidyr", "sf", 
              "ggrepel", "rnaturalearth", "rnaturalearthdata", "knitr", "spdep",
              "tmap", "cols4all")

# Install any that are missing
missing <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(missing)) install.packages(missing)

# Load all packages
invisible(lapply(packages, library, character.only = TRUE))

```

# Introduction

This project was a comprehensive analysis of the spatial distribution of coinage originating from various mints and subsequently deposited in hoards across the Roman world between approximately 500 BCE and 200 CE. By examining patterns in coin dispersal and quantifying the distances between points of minting and findspots, the study aimed to examine the broader dynamics of monetary circulation, and economic integration within the Roman economy. The ultimate objective was to generate insights into the mechanisms of coin movement and to contribute to our understanding of the structure and function of the ancient Roman economic system.

The first step that I'd like to look at is the probability of a coin existing in a certain location base on hoard finds.

Note that there are several errors and mislabeled figures in this.  This is for discussion purposes only.

# Methodology

## Data Source

For the initial analysis, the data from the [Coin Hoards of the Roman Republic](https://numismatics.org/chrr/) was accessed.  This [dataset](https://numismatics.org/chrr/pages/background) is based of the work of Crawford (1969), as enhanced by Gruber and Lockyear.

This data can be accessed via the website's [APIs](https://numismatics.org/chrr/apis) or via the [SPARQL endpoint](https://nomisma.org/sparql/) at [Nomisma](https://nomisma.org).  Not all hoards were appropriate for analysis.  This initial analysis only included hoard findspots that had the following:

*  Geolocation of hoard
*  At least 1 coin with a known mint
*  Known mint geolocation

The findspot information was mostly within a 5 kilometer radius of the findspot.  Some was 10 km, but that was less often.  For security reasons, the exact geolocation was never directly published to prevent theft and looting. 

For now, all the findspots meeting the criteria were used, but this may be narrowed in the future.

## Data Acquisition

To acquire the data, first a list of all the hoards in the CHRR dataset was gathered from the SPARQL endpoint.

```

PREFIX dcterms: <http://purl.org/dc/terms/>
PREFIX nmo: <http://nomisma.org/ontology#>

SELECT DISTINCT ?hoardID
WHERE {
  ?hoard a nmo:Hoard .
  FILTER(STRSTARTS(STR(?hoard), "http://numismatics.org/chrr/id/"))
  BIND(REPLACE(STR(?hoard), "http://numismatics.org/chrr/id/", "") AS ?hoardID)
}
ORDER BY ?hoardID

```

Using the list of three digit hoard identifiers from this list, an R program was written to download all of the identified hoards using the schema:

```
# ---- 3. Define File Formats and URI Templates ----
formats <- list(
  xml     = "http://numismatics.org/chrr/id/XXX",
  rdf     = "https://numismatics.org/chrr/id/XXX.rdf",
  ttl     = "https://numismatics.org/chrr/id/XXX.ttl",
  jsonld  = "https://numismatics.org/chrr/id/XXX.jsonld",
  geojson = "https://numismatics.org/chrr/id/XXX.geojson"
)
```
‘XXX’ was replaced by the three digit hoard identifier.

Example hoard identifier list:
```
...
AVO
AVV
AVZ
AZA
AZN
AZU
...
```

All of the RDF/XML, TTL, JSON-LD, and GeoJSON data were gathered for the hoards.  The code for this is not included in this file.

From this dataset, all the coin identifiers in the dataset were extracted.  The URIs were in the form:

```

# ---- 3. Define Format URIs ----
format_urls <- list(
  xml      = "http://numismatics.org/crro/id/XXX.xml",
  rdf      = "https://numismatics.org/crro/id/XXX.rdf",
  ttl      = "https://numismatics.org/crro/id/XXX.ttl",
  jsonld   = "https://numismatics.org/crro/id/XXX.jsonld",
  geojson  = "https://numismatics.org/crro/id/XXX.geojson",
  manifest = "http://numismatics.org/crro/manifest/XXX"
)

```

The coin ids, which replaced the XXX above, were in the form:

```
...
rrc-210.1
rrc-214.1b
rrc-232.1
rrc-235.1c
rrc-236.1a
rrc-243.1
rrc-247.1
rrc-260.1
rrc-270.1
...

```
All of the RDF/XML, TTL, JSON-LD, and GeoJSON data were gathered for the hoards.  The code for this is not included in this file.

In addition

## Data Processing

The a sample of the initial set of data looks like:

```{r hoard_rome_data}

# Load the data
hoards_df <- read_csv("/Users/john/Library/Mobile Documents/com~apple~CloudDocs/Home/John/GIS/Roman Italy GIS/Coin Project/chrr_hoards/hoard_geojson/combined_hoards_with_distance.csv")

# Filter for Rome mint, take first 20 rows, keep all columns
rome_subset <- hoards_df %>%
  filter(mint_name == "Rome") %>%
  slice_head(n = 10)

# Print as a nicely formatted table
kable(rome_subset, caption = "First 20 Hoards with Rome as Mint")
```

This is limited only to hoards with coins from the Rome mint, and the distance is crudely calculated as the great circle distance.  We expect to use [ORBIS](https://orbis.stanford.edu) to more accurately model transportation networks and distances.  

There is more granular data that includes *Terminus Ante Quem* (closing date), specific coin types and authorities, and dates.  This has not yet been combined into the data set.  

It is expected that there would be some spatial autocorrelation of the data since there is the expectation that coins would not be distributed along whatever routes they took to their final destination in the hoard.  

# Results

## Mints

```{r mint_locations, echo=FALSE}
plot_geojson_map <- function(filepath, title = "GeoJSON Map", labels = FALSE) {
  # Read GeoJSON
  data <- st_read(filepath, quiet = TRUE)
  data <- st_transform(data, crs = 4326)

  # Bounding box with padding
  bbox <- st_bbox(data)
  padding <- 0.5
  xlim <- c(bbox$xmin - padding, bbox$xmax + padding)
  ylim <- c(bbox$ymin - padding, bbox$ymax + padding)

  # Load basemap (countries)
  basemap <- ne_countries(scale = "medium", returnclass = "sf") %>%
    st_transform(4326)

  # Create base plot
  p <- ggplot() +
    geom_sf(data = basemap, fill = "gray95", color = "gray70") +
    geom_sf(data = data, aes(geometry = geometry), color = "darkred", size = 2) +
    coord_sf(xlim = xlim, ylim = ylim) +
    labs(title = title, x = "Longitude", y = "Latitude") +
    theme_minimal()

  # Add labels offset from points
  if (labels && "name" %in% names(data)) {
    centroids <- st_centroid(data)
    coords <- st_coordinates(centroids)
    label_df <- data.frame(coords, name = data$name)

    p <- p +
      geom_text_repel(data = label_df,
                      aes(x = X, y = Y, label = name),
                      size = 3,
                      min.segment.length = 0,
                      box.padding = 0.3,
                      segment.color = "gray50")
  }

  return(p)
}

# mint geojson data
filepath <- "/Users/john/Library/Mobile Documents/com~apple~CloudDocs/Home/John/GIS/Roman Italy GIS/Coin Project/rmd_data/mints.geojson"

# Plot with title and labels
plot_geojson_map(filepath, title = "Mint Locations", labels = TRUE)

```

## All Hoard Findspots

```{r hoard_locations, echo=FALSE}

# hoard data
filepath <- "/Users/john/Library/Mobile Documents/com~apple~CloudDocs/Home/John/GIS/Roman Italy GIS/Coin Project/rmd_data/findspots.geojson"

# Plot with title and labels
plot_geojson_map(filepath, title = "Hoard Locations", labels = FALSE)

```

```{r hoard_heatmap, echo=FALSE}

plot_geojson_heatmap <- function(filepath, title = "GeoJSON Heatmap") {
  # Read GeoJSON
  data <- st_read(filepath, quiet = TRUE)
  data <- st_transform(data, crs = 4326)

  # Get bounding box with padding
  bbox <- st_bbox(data)
  padding <- 0.5
  xlim <- c(bbox$xmin - padding, bbox$xmax + padding)
  ylim <- c(bbox$ymin - padding, bbox$ymax + padding)

  # Load basemap
  basemap <- ne_countries(scale = "medium", returnclass = "sf") %>%
    st_transform(4326)

  # Extract point coordinates from sf
  coords <- st_coordinates(data)
  point_df <- as.data.frame(coords)

  # Heatmap plot
  p <- ggplot() +
    geom_sf(data = basemap, fill = "gray95", color = "gray70") +
    stat_density_2d(
      data = point_df,
      aes(x = X, y = Y, fill = after_stat(level)),
      geom = "polygon",
      alpha = 0.7,
      bins = 30
    ) +
    scale_fill_viridis_c(option = "magma", name = "Density") +
    geom_point(data = point_df, aes(x = X, y = Y), color = "darkred", size = 1.2, alpha = 0.6) +
    coord_sf(xlim = xlim, ylim = ylim, expand = FALSE) +
    labs(title = title, x = "Longitude", y = "Latitude") +
    theme_minimal()

  return(p)
}

filepath <- "/Users/john/Library/Mobile Documents/com~apple~CloudDocs/Home/John/GIS/Roman Italy GIS/Coin Project/rmd_data/findspots.geojson"

plot_geojson_heatmap(filepath, title = "Heatmap of Hoard Locations")

```
## Spatial Autocorrelation

```{r spatial_auto_improved, echo=FALSE}

# Load data
hoards_df <- readr::read_csv("/Users/john/Library/Mobile Documents/com~apple~CloudDocs/Home/John/GIS/Roman Italy GIS/Coin Project/chrr_hoards/hoard_geojson/combined_hoards_with_distance.csv")

# Step 1: Filter to Rome mint and create presence indicator
rome_df <- hoards_df %>%
  filter(mint_name == "Rome") %>%
  mutate(presence = ifelse(!is.na(mint_average_count) & mint_average_count > 0, 1, 0)) %>%
  filter(!is.na(hoard_lat) & !is.na(hoard_lon))

# Data quality checks
cat("Data Quality Summary:\n")
cat("Total hoards:", nrow(rome_df), "\n")
cat("Presence distribution:\n")
print(table(rome_df$presence))
cat("Missing coordinates:", sum(is.na(rome_df$hoard_lat) | is.na(rome_df$hoard_lon)), "\n")

# Check for very imbalanced data
presence_prop <- mean(rome_df$presence)
cat("Proportion with Rome mint presence:", round(presence_prop, 3), "\n")

# Step 2: Convert to sf object (WGS84) and project
rome_sf <- st_as_sf(rome_df, coords = c("hoard_lon", "hoard_lat"), crs = 4326)
# Project to metric CRS for consistent distance calculations (Web Mercator)
rome_proj <- st_transform(rome_sf, 3857)

# Get coordinates for spatial analysis
coords <- st_coordinates(rome_proj)

# Step 3: Determine optimal distance threshold
# Test multiple distance thresholds to find optimal one
distances <- c(100000, 150000, 200000, 250000, 300000)  # 100-300 km
cat("\nTesting multiple distance thresholds:\n")

moran_results <- data.frame()
for(dist in distances) {
  nb_temp <- dnearneigh(coords, d1 = 0, d2 = dist)
  
  # Check for islands (points with no neighbors)
  islands <- sum(card(nb_temp) == 0)
  
  if(islands == 0) {
    lw_temp <- nb2listw(nb_temp, style = "W", zero.policy = TRUE)
    moran_temp <- moran.test(rome_proj$presence, lw_temp, zero.policy = TRUE)
    
    result <- data.frame(
      distance_km = dist/1000,
      moran_i = moran_temp$estimate[1],
      p_value = moran_temp$p.value,
      islands = islands,
      avg_neighbors = mean(card(nb_temp))
    )
  } else {
    result <- data.frame(
      distance_km = dist/1000,
      moran_i = NA,
      p_value = NA,
      islands = islands,
      avg_neighbors = NA
    )
  }
  
  moran_results <- rbind(moran_results, result)
}

print(moran_results)

# Choose optimal distance (modify based on results above)
# Using 200km as default, but adjust based on your results
optimal_distance <- 200000

# Step 4: Create neighbors and spatial weights with chosen distance
nb <- dnearneigh(coords, d1 = 0, d2 = optimal_distance)
cat("\nSpatial neighborhood summary:\n")
cat("Distance threshold:", optimal_distance/1000, "km\n")
cat("Number of points with no neighbors:", sum(card(nb) == 0), "\n")
cat("Average number of neighbors:", round(mean(card(nb)), 2), "\n")
cat("Range of neighbors:", min(card(nb)), "-", max(card(nb)), "\n")

# Create spatial weights (row-standardized)
lw <- nb2listw(nb, style = "W", zero.policy = TRUE)

# Also create binary weights for comparison
lw_binary <- nb2listw(nb, style = "B", zero.policy = TRUE)

# Step 5: Global Moran's I tests
cat("\nGlobal Moran's I Results:\n")
moran_result_w <- moran.test(rome_proj$presence, lw, zero.policy = TRUE)
moran_result_b <- moran.test(rome_proj$presence, lw_binary, zero.policy = TRUE)

cat("Row-standardized weights:\n")
print(moran_result_w)
cat("\nBinary weights:\n")
print(moran_result_b)

# Step 6: Local Moran's I analysis
cat("\nComputing Local Moran's I...\n")
local_moran <- localmoran(rome_proj$presence, lw, zero.policy = TRUE)

# Add results back to the spatial object
# Get column name that starts with "Pr("
p_col <- grep("^Pr\\(", colnames(local_moran), value = TRUE)

rome_proj$Ii     <- local_moran[, "Ii"]
rome_proj$Z_Ii   <- local_moran[, "Z.Ii"]
rome_proj$p_Ii   <- local_moran[, p_col]
rome_proj$Var_Ii <- local_moran[, "Var.Ii"]

# Multiple comparison correction
rome_proj$p_Ii_adj <- p.adjust(rome_proj$p_Ii, method = "fdr")

# Calculate confidence intervals
rome_proj$ci_lower <- rome_proj$Ii - 1.96 * sqrt(rome_proj$Var_Ii)
rome_proj$ci_upper <- rome_proj$Ii + 1.96 * sqrt(rome_proj$Var_Ii)

# Classify clusters using original p-values
rome_proj$cluster <- "Not significant"
rome_proj$cluster[rome_proj$presence == 1 & rome_proj$Ii > 0 & rome_proj$p_Ii < 0.05] <- "High-High"
rome_proj$cluster[rome_proj$presence == 0 & rome_proj$Ii > 0 & rome_proj$p_Ii < 0.05] <- "Low-Low"
rome_proj$cluster[rome_proj$presence == 1 & rome_proj$Ii < 0 & rome_proj$p_Ii < 0.05] <- "High-Low"
rome_proj$cluster[rome_proj$presence == 0 & rome_proj$Ii < 0 & rome_proj$p_Ii < 0.05] <- "Low-High"

# Classify clusters using adjusted p-values
rome_proj$cluster_adj <- "Not significant"
rome_proj$cluster_adj[rome_proj$presence == 1 & rome_proj$Ii > 0 & rome_proj$p_Ii_adj < 0.05] <- "High-High"
rome_proj$cluster_adj[rome_proj$presence == 0 & rome_proj$Ii > 0 & rome_proj$p_Ii_adj < 0.05] <- "Low-Low"
rome_proj$cluster_adj[rome_proj$presence == 1 & rome_proj$Ii < 0 & rome_proj$p_Ii_adj < 0.05] <- "High-Low"
rome_proj$cluster_adj[rome_proj$presence == 0 & rome_proj$Ii < 0 & rome_proj$p_Ii_adj < 0.05] <- "Low-High"

# Add significance levels
rome_proj$sig_level <- case_when(
  rome_proj$p_Ii < 0.01 ~ "p < 0.01",
  rome_proj$p_Ii < 0.05 ~ "p < 0.05",
  TRUE ~ "Not significant"
)

# Summary of clusters
cat("\nCluster Summary (original p-values):\n")
print(table(rome_proj$cluster))
cat("\nCluster Summary (FDR-adjusted p-values):\n")
print(table(rome_proj$cluster_adj))
cat("\nSignificance levels:\n")
print(table(rome_proj$sig_level))

# Step 7: Visualization
tmap_mode("view")

# LISA map with original p-values
lisa_map1 <- tm_shape(rome_proj) +
  tm_symbols(fill = "cluster", 
             fill.scale = tm_scale(values = c("gray", "red", "blue", "orange", "purple")), 
             size = 0.8) +
  tm_basemap("OpenStreetMap") +
  tm_title(paste("Local Moran's I Cluster Map (Rome Mint) - Distance:", optimal_distance / 1000, "km"))

# LISA map with adjusted p-values
lisa_map2 <- tm_shape(rome_proj) +
  tm_symbols(fill = "cluster_adj", 
             fill.scale = tm_scale(values = c("gray", "red", "blue", "orange", "purple")), 
             size = 0.8) +
  tm_basemap("OpenStreetMap") +
  tm_title(paste("Local Moran's I Cluster Map (FDR-adjusted) - Distance:", optimal_distance / 1000, "km"))

# Z-score map
# Use tmap mode
tmap_mode("view")  # or "plot" if you want a static plot

# Make sure rome_proj is in EPSG:4326 if using basemaps
rome_proj_wgs <- st_transform(rome_proj, 4326)

# Define the z_map
z_map <- tm_shape(rome_proj_wgs) +
  tm_symbols(
    fill = "Z_Ii",
    size = 0.8,
    fill.scale = tm_scale_continuous(
      values = c4a("brewer.rd_bu", n = 9),
      midpoint = 0
    )
  ) +
  tm_basemap("OpenStreetMap") +
  tm_title("Z-Scores of Local Moran's I (Rome Mint Hoards)")

# Display
z_map

# Display maps
print(lisa_map1)
print(lisa_map2)
print(z_map)

## Alternative ggplot visualization

# Load and transform basemap to match rome_proj
world <- ne_countries(scale = "medium", returnclass = "sf")
world <- st_transform(world, st_crs(rome_proj))
bbox <- st_bbox(rome_proj)

# Plot with bounding box
z_ggplot <- ggplot() +
  geom_sf(data = world, fill = "gray95", color = "gray70", size = 0.2) +
  geom_sf(data = rome_proj, aes(color = Z_Ii), size = 2) +
  scale_color_gradient2(low = "blue", mid = "white", high = "red", 
                        midpoint = 0, name = "Z-Score (Ii)") +
  labs(
    title = paste("Z-Scores of Local Moran's I (Rome Mint Hoards) - Distance:", optimal_distance / 1000, "km"),
    subtitle = paste("Global Moran's I =", round(moran_result_w$estimate[1], 4), 
                     ", p-value =", round(moran_result_w$p.value, 4))
  ) +
  coord_sf(xlim = c(bbox["xmin"], bbox["xmax"]),
         ylim = c(bbox["ymin"], bbox["ymax"]),
         expand = FALSE) +
  theme_minimal()

print(z_ggplot)

# Step 8: Alternative analysis with k-nearest neighbors
cat("\nAlternative analysis with k-nearest neighbors:\n")
k_values <- c(6, 8, 10, 12)
knn_results <- data.frame()
for(k in k_values) {
  nb_knn <- knn2nb(knearneigh(coords, k = k))
  lw_knn <- nb2listw(nb_knn, style = "W", zero.policy = TRUE)
  moran_knn <- moran.test(rome_proj$presence, lw_knn, zero.policy = TRUE)
  
  result <- data.frame(
    k = k,
    moran_i = moran_knn$estimate[1],
    p_value = moran_knn$p.value
  )
  
  knn_results <- rbind(knn_results, result)
}

print(knn_results)

# Step 9: Diagnostics and validation
cat("\nDiagnostics:\n")
cat("Distribution of presence variable:\n")
print(summary(rome_proj$presence))

cat("\nLocal Moran's I statistics summary:\n")
print(summary(rome_proj$Ii))

cat("\nSignificant clusters by type:\n")
sig_clusters <- rome_proj[rome_proj$p_Ii < 0.05, ]
if(nrow(sig_clusters) > 0) {
  print(table(sig_clusters$cluster))
} else {
  cat("No significant clusters found\n")
}

# Save results for further analysis
# rome_proj can be saved as needed
# st_write(rome_proj, "rome_lisa_results.shp")
```

## Kriging / probability surface

```{r kriging, echo = TRUE}



```

This is not functional.  I have developed some code but it does not work well.

I am trying to use indicator Kriging, but I am running into trouble excuting the analysis.  I only have places that have coins, and a few that don't have coins from the Rome mint.  I don't think I have enough data.  

## Distance Decay

```{r dist_decay}

# Roman Coin Probability Surface Analysis with Hex Binning
# Load required libraries
library(sf)
library(dplyr)
library(ggplot2)
library(readr)
library(viridis)

# Try to load optional basemap packages
basemap_packages <- c("rnaturalearth", "rnaturalearthdata", "maps")
available_packages <- sapply(basemap_packages, function(pkg) {
  suppressWarnings(require(pkg, character.only = TRUE, quietly = TRUE))
})

if(!any(available_packages)) {
  warning("No basemap packages available. Install 'rnaturalearth' or 'maps' for geographic context.")
}

# Resolve potential conflicts
select <- dplyr::select
filter <- dplyr::filter
mutate <- dplyr::mutate

# Read and prepare data
data <- readr::read_csv("/Users/john/Library/Mobile Documents/com~apple~CloudDocs/Home/John/GIS/Roman Italy GIS/Coin Project/chrr_hoards/hoard_geojson/combined_hoards_with_distance.csv")

# Focus on Rome mint only
rome_data <- data %>%
  dplyr::filter(mint_name == "Rome") %>%
  dplyr::select(hoard_id, hoard_name, hoard_lat, hoard_lon, 
                mint_average_count, mint_hoard_distance_km)

# Convert findspots to spatial points
findspots_sf <- st_as_sf(rome_data, 
                         coords = c("hoard_lon", "hoard_lat"), 
                         crs = 4326)

# Create hexagonal grid function
create_hex_grid <- function(bbox, hex_size_km = 75) {
  # Convert to projected CRS for equal area hexagons (Europe-focused)
  bbox_proj <- st_transform(st_as_sfc(bbox), crs = 3035)
  
  # Create hex grid
  hex_grid <- st_make_grid(bbox_proj, 
                           cellsize = hex_size_km * 1000, # convert to meters
                           square = FALSE) # hexagonal
  
  # Convert back to WGS84 and add IDs
  hex_grid <- st_sf(hex_id = 1:length(hex_grid), 
                    geometry = st_transform(hex_grid, crs = 4326))
  return(hex_grid)
}

# Create study area bounding box (expand around findspots)
bbox <- st_bbox(findspots_sf)
bbox_expanded <- bbox + c(-2, -2, 2, 2)  # expand by 2 degrees
study_area <- st_as_sfc(st_bbox(bbox_expanded, crs = st_crs(findspots_sf)))

# Create hex grid
hex_grid <- create_hex_grid(bbox_expanded, hex_size_km = 75)

# Spatial join: assign each findspot to a hex
findspots_hex <- st_join(findspots_sf, hex_grid)

# Aggregate data by hex
hex_summary <- findspots_hex %>%
  sf::st_drop_geometry() %>%
  dplyr::group_by(hex_id) %>%
  dplyr::summarise(
    total_coins = sum(mint_average_count, na.rm = TRUE),
    n_findspots = n(),
    avg_distance_to_rome = mean(mint_hoard_distance_km, na.rm = TRUE),
    .groups = 'drop'
  )

# Join aggregated data back to hex grid
hex_grid <- hex_grid %>%
  dplyr::left_join(hex_summary, by = "hex_id") %>%
  dplyr::mutate(
    total_coins = ifelse(is.na(total_coins), 0, total_coins),
    has_findspots = !is.na(n_findspots)
  )

# Calculate distance from each hex centroid to Rome
rome_coords <- st_sfc(st_point(c(12.5, 41.9)), crs = 4326)

hex_grid <- hex_grid %>%
  dplyr::mutate(
    dist_to_rome = as.numeric(sf::st_distance(sf::st_centroid(.), rome_coords)) / 1000
  )

# Fit distance decay model using hexes with actual data
model_data <- hex_grid %>%
  dplyr::filter(has_findspots == TRUE & total_coins > 0) %>%
  sf::st_drop_geometry()

# Check if we have enough data for modeling
if(nrow(model_data) < 3) {
  stop("Not enough data points for modeling. Need at least 3 hexes with coin data.")
}

# Fit exponential decay model
# Try different starting parameters if the first attempt fails
tryCatch({
  decay_model <- nls(total_coins ~ a * exp(-b * dist_to_rome), 
                     data = model_data,
                     start = list(a = max(model_data$total_coins), b = 0.001))
}, error = function(e) {
  # Alternative: simple linear model on log scale
  decay_model <- lm(log(total_coins + 1) ~ dist_to_rome, data = model_data)
})

# Predict for all hexes
if(class(decay_model)[1] == "nls") {
  hex_grid$predicted_coins <- predict(decay_model, 
                                      newdata = data.frame(dist_to_rome = hex_grid$dist_to_rome))
} else {
  # For linear model, back-transform predictions
  hex_grid$predicted_coins <- exp(predict(decay_model, 
                                          newdata = data.frame(dist_to_rome = hex_grid$dist_to_rome))) - 1
}

# Create probability surface (normalize to 0-1)
hex_grid$probability <- pmax(0, hex_grid$predicted_coins) / max(pmax(0, hex_grid$predicted_coins))

# Combine observed and predicted values
hex_grid$final_coins <- ifelse(hex_grid$has_findspots, 
                               hex_grid$total_coins, 
                               hex_grid$predicted_coins)

hex_grid$final_probability <- hex_grid$final_coins / max(hex_grid$final_coins)

# Get basemap data (with error handling)
world <- NULL
basemap_available <- FALSE

# Try Natural Earth first
if(available_packages["rnaturalearth"]) {
  tryCatch({
    world <- rnaturalearth::ne_countries(scale = "medium", returnclass = "sf")
    basemap_available <- TRUE
  }, error = function(e) {
    message("Natural Earth data not available, trying maps package...")
  })
}

# Try maps package as fallback
if(!basemap_available && available_packages["maps"]) {
  tryCatch({
    world_map <- maps::map("world", fill = TRUE, plot = FALSE)
    world <- sf::st_as_sf(world_map)
    basemap_available <- TRUE
  }, error = function(e) {
    message("Maps package not working, proceeding without basemap...")
  })
}

# Create study area boundary for clipping
study_bbox <- sf::st_bbox(hex_grid)
study_area_poly <- sf::st_as_sfc(study_bbox)

# Create visualization with optional basemap
if(basemap_available) {
  p1 <- ggplot() +
    # Add basemap first
    geom_sf(data = world, fill = "grey90", color = "grey95", size = 0.2) +
    # Add hex grid
    geom_sf(data = hex_grid, aes(fill = final_probability), 
            color = "white", size = 0.1, alpha = 0.8) +
    scale_fill_viridis_c(name = "Coin\nProbability", 
                         trans = "sqrt",
                         option = "turbo",
                         labels = scales::percent) +
    # Add findspot points
    geom_sf(data = findspots_sf, size = 1, alpha = 0.9, color = "white") +
    # Add Rome
    geom_sf(data = rome_coords, size = 4, color = "red", shape = 18) +
    # Set map extent to study area
    coord_sf(xlim = c(study_bbox["xmin"], study_bbox["xmax"]),
             ylim = c(study_bbox["ymin"], study_bbox["ymax"]),
             expand = FALSE) +
    theme_void() +
    theme(
      legend.position = "right",
      plot.title = element_text(size = 14, hjust = 0.5),
      plot.subtitle = element_text(size = 12, hjust = 0.5),
      panel.background = element_rect(fill = "lightblue", color = NA)
    ) +
    labs(title = "Probability Surface for Roman Coins",
         subtitle = "Hexagonal binning with distance decay model from Rome")
} else {
  # Fallback map without basemap
  p1 <- ggplot(hex_grid) +
    geom_sf(aes(fill = final_probability), color = "white", size = 0.1) +
    scale_fill_viridis_c(name = "Coin\nProbability", 
                         trans = "sqrt",
                         option = "turbo",
                         labels = scales::percent) +
    geom_sf(data = findspots_sf, size = 1, alpha = 0.8, color = "white") +
    geom_sf(data = rome_coords, size = 4, color = "red", shape = 18) +
    theme_void() +
    theme(
      legend.position = "right",
      plot.title = element_text(size = 14, hjust = 0.5),
      plot.subtitle = element_text(size = 12, hjust = 0.5)
    ) +
    labs(title = "Probability Surface for Roman Coins",
         subtitle = "Hexagonal binning with distance decay model from Rome",
         caption = "Note: Install 'rnaturalearth' or 'maps' package for geographic context")
}

print(p1)

# Create enhanced version if basemap is available
if(basemap_available) {
  p1_labeled <- ggplot() +
    # Add basemap
    geom_sf(data = world, fill = "grey90", color = "grey95", size = 0.2) +
    # Add hex grid
    geom_sf(data = hex_grid, aes(fill = final_probability), 
            color = "white", size = 0.1, alpha = 0.8) +
    scale_fill_viridis_c(name = "Coin\nProbability", 
                         trans = "sqrt",
                         option = "plasma",
                         labels = scales::percent) +
    # Add findspot points
    geom_sf(data = findspots_sf, size = 1.2, alpha = 0.9, color = "white") +
    # Add Rome with label
    geom_sf(data = rome_coords, size = 4, color = "red", shape = 18) +
    annotate("text", x = 12.5, y = 41.2, label = "Rome", 
             color = "red", fontface = "bold", size = 3) +
    # Set map extent
    coord_sf(xlim = c(study_bbox["xmin"], study_bbox["xmax"]),
             ylim = c(study_bbox["ymin"], study_bbox["ymax"]),
             expand = FALSE) +
    theme_void() +
    theme(
      legend.position = "right",
      plot.title = element_text(size = 14, hjust = 0.5),
      plot.subtitle = element_text(size = 12, hjust = 0.5),
      panel.background = element_rect(fill = "lightblue", color = NA)
    ) +
    labs(title = "Roman Coin Distribution Probability",
         subtitle = "Based on distance decay modeling from Rome",
         caption = "White dots = Coin findspots | Red diamond = Rome")
  
  print(p1_labeled)
}

# Summary statistics
cat("Analysis Summary:\n")
cat("=================\n")
cat("Total findspots:", nrow(findspots_sf), "\n")
cat("Total coins from Rome:", sum(rome_data$mint_average_count), "\n")
cat("Hexes with data:", sum(hex_grid$has_findspots, na.rm = TRUE), "\n")
cat("Total hexes:", nrow(hex_grid), "\n")
cat("Max distance to Rome:", round(max(hex_grid$dist_to_rome), 2), "km\n")
cat("Min distance to Rome:", round(min(hex_grid$dist_to_rome), 2), "km\n")

# Model diagnostics
if(class(decay_model)[1] == "nls") {
  cat("\nDistance Decay Model (Exponential):\n")
  cat("===================================\n")
  print(summary(decay_model))
} else {
  cat("\nDistance Decay Model (Linear on log scale):\n")
  cat("==========================================\n")
  print(summary(decay_model))
}

# Create distance vs coins plot
p2 <- ggplot(model_data, aes(x = dist_to_rome, y = total_coins)) +
  geom_point(alpha = 0.7, size = 2) +
  geom_smooth(method = "loess", se = TRUE, color = "red") +
  scale_y_log10() +
  labs(title = "Distance Decay Relationship",
       x = "Distance to Rome (km)",
       y = "Total Coins (log scale)") +
  theme_minimal()

print(p2)

# Export results (optional)
# hex_results <- hex_grid %>%
#   dplyr::select(hex_id, dist_to_rome, total_coins, predicted_coins, 
#          final_probability, has_findspots) %>%
#   sf::st_drop_geometry()
# 
# readr::write_csv(hex_results, "roman_coin_probability_results.csv")

```

# Bibliography

Crawford, M. H. 1969. Roman Republican Coin Hoards. London: Royal Numismatic Society.
Esty, W. W. (1997). Statistics in Numismatics. In: C. Morrison and B. Kluge (eds.). A Survey of Numismatic Research 1990-1995. International Association of Professional Numismatists, Special Publication n. 13, Berlin.

Finley, Moses I. 1973. The Ancient Economy. Berkeley: University of California Press.

Gruber, E. W. 2013. Recent Advancements in Roman Numismatics. Master’s dissertation, University of Virginia.

Gruber, E. W. and K. Lockyear forthcoming. “From dBase III+ to the semantic web: twenty-five years of the Coin Hoards of the Roman Republic database.” Proceedings of CAA2013 held in Perth, March 2013.

Haddad, E., & Araújo, I. (2022). Regional Science Meets the Past: What Do Coin Finds Tell Us About the Ancient Spatial Economy? (No. 2-2022). Núcleo de Economia Regional e Urbana da Universidade de São Paulo (NEREUS).

Lockyear, K. 1989. A Statistical Investigation of Roman Republican Coin Hoards. Master’s dissertation, University of Southampton.

Lockyear, K. 1996. Multivariate Money. A statistical analysis of Roman Republican coin hoards with special reference to material from Romania. Ph.D. thesis, Institute of Archaeology, University College London.

Lockyear, K. 2007. Patterns and Process in Late Roman Republican Coin Hoards, 157–2 BC. Oxford: British Archaeological Reports.

Lockyear, Kris (2013). Coin hoards of the Roman Republic Online, version X. New York: American Numismatic Society. Data retrieved from on ...

Lockyear, Kris. 2007. Patterns and Process in Late Roman Republican Coin Hoards, 157-2 BC. Ann Arbor, MI: University of Michigan Press. doi:10.30861/9781407301648.

# R Configuration

```{r r_configuration}
sessioninfo::session_info()
```
